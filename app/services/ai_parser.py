"""
AI Parser Service for structuring medical analysis data.
Uses OpenAI GPT to extract and normalize biomarker values from OCR text.
"""

import json
import logging
import re
from typing import Dict, List, Optional, Any

from openai import AsyncOpenAI

from app.core.config import settings
from app.models.analysis import LabProvider

logger = logging.getLogger(__name__)


# System prompt for GPT
EXTRACTION_SYSTEM_PROMPT = """–¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –∏–∑–≤–ª–µ—á—å –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–æ–≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –±–∏–æ–º–∞—Ä–∫–µ—Ä–∞—Ö.

–ü—Ä–∞–≤–∏–ª–∞:
1. –ò–∑–≤–ª–µ–∫–∞–π –¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞, –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –¥–∞–Ω–Ω—ã–µ
2. –ü—Ä–∏–≤–æ–¥–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –∫–æ–¥–∞–º (HGB, RBC, WBC, FE, B12, D3, TSH –∏ —Ç.–¥.)
3. –°–æ—Ö—Ä–∞–Ω—è–π –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è –≤ –ø–æ–ª–µ raw_name
4. ‚ö†Ô∏è –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏–∑–≤–ª–µ–∫–∞–π —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (ref_min, ref_max) –¥–ª—è –ö–ê–ñ–î–û–ì–û –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è! –û–Ω–∏ –æ–±—ã—á–Ω–æ –∏–¥—É—Ç –ø–æ—Å–ª–µ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª –∏–ª–∏ –¥–µ—Ñ–∏—Å. –ü—Ä–∏–º–µ—Ä—ã: "13.6 % 12.0-13.6", "154 –≥/–ª 135-169"
5. –û–ø—Ä–µ–¥–µ–ª—è–π –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
6. –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –∏–∑–≤–ª–µ—á—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, –ø—Ä–æ–ø—É—Å–∫–∞–π –µ–≥–æ

–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∫–æ–¥—ã –±–∏–æ–º–∞—Ä–∫–µ—Ä–æ–≤:

–ì–ï–ú–ê–¢–û–õ–û–ì–ò–Ø:
- HGB (–ì–µ–º–æ–≥–ª–æ–±–∏–Ω)
- RBC (–≠—Ä–∏—Ç—Ä–æ—Ü–∏—Ç—ã)
- WBC (–õ–µ–π–∫–æ—Ü–∏—Ç—ã)
- PLT (–¢—Ä–æ–º–±–æ—Ü–∏—Ç—ã)
- HCT (–ì–µ–º–∞—Ç–æ–∫—Ä–∏—Ç)
- MCV (–°—Ä–µ–¥–Ω–∏–π –æ–±—ä–µ–º —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç–∞)
- MCH (–°—Ä–µ–¥–Ω–µ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≥–µ–º–æ–≥–ª–æ–±–∏–Ω–∞)
- MCHC (–°—Ä–µ–¥–Ω—è—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è –≥–µ–º–æ–≥–ª–æ–±–∏–Ω–∞)
- RDW (–®–∏—Ä–∏–Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç–æ–≤)
- MPV (–°—Ä–µ–¥–Ω–∏–π –æ–±—ä–µ–º —Ç—Ä–æ–º–±–æ—Ü–∏—Ç–æ–≤)
- PCT (–¢—Ä–æ–º–±–æ–∫—Ä–∏—Ç)
- ESR (–°–û–≠)
- NEUT (–ù–µ–π—Ç—Ä–æ—Ñ–∏–ª—ã)
- LYMPH (–õ–∏–º—Ñ–æ—Ü–∏—Ç—ã)
- MONO (–ú–æ–Ω–æ—Ü–∏—Ç—ã)
- EOS (–≠–æ–∑–∏–Ω–æ—Ñ–∏–ª—ã)
- BASO (–ë–∞–∑–æ—Ñ–∏–ª—ã)

–ë–ò–û–•–ò–ú–ò–Ø:
- GLU (–ì–ª—é–∫–æ–∑–∞)
- TP (–û–±—â–∏–π –±–µ–ª–æ–∫)
- ALB (–ê–ª—å–±—É–º–∏–Ω)
- LDH (–õ–î–ì, –ª–∞–∫—Ç–∞—Ç–¥–µ–≥–∏–¥—Ä–æ–≥–µ–Ω–∞–∑–∞)
- CK (–ö–§–ö, –∫—Ä–µ–∞—Ç–∏–Ω–∫–∏–Ω–∞–∑–∞)
- AMY (–ê–º–∏–ª–∞–∑–∞)
- LIPA (–õ–∏–ø–∞–∑–∞)

–ü–ï–ß–ï–ù–¨:
- ALT (–ê–õ–¢)
- AST (–ê–°–¢)
- GGT (–ì–ì–¢–ü, –≥–∞–º–º–∞-–≥–ª—É—Ç–∞–º–∏–ª—Ç—Ä–∞–Ω—Å—Ñ–µ—Ä–∞–∑–∞)
- ALP (–©–µ–ª–æ—á–Ω–∞—è —Ñ–æ—Å—Ñ–∞—Ç–∞–∑–∞)
- BILI (–ë–∏–ª–∏—Ä—É–±–∏–Ω –æ–±—â–∏–π)
- DBILI (–ë–∏–ª–∏—Ä—É–±–∏–Ω –ø—Ä—è–º–æ–π)

–ü–û–ß–ö–ò:
- CREA (–ö—Ä–µ–∞—Ç–∏–Ω–∏–Ω)
- UREA (–ú–æ—á–µ–≤–∏–Ω–∞)
- UA (–ú–æ—á–µ–≤–∞—è –∫–∏—Å–ª–æ—Ç–∞)
- GFR (–°–ö–§)

–õ–ò–ü–ò–î–´:
- CHOL (–•–æ–ª–µ—Å—Ç–µ—Ä–∏–Ω –æ–±—â–∏–π)
- HDL (–õ–ü–í–ü)
- LDL (–õ–ü–ù–ü)
- TG (–¢—Ä–∏–≥–ª–∏—Ü–µ—Ä–∏–¥—ã)

–ú–ò–ù–ï–†–ê–õ–´:
- FE (–ñ–µ–ª–µ–∑–æ)
- FERR (–§–µ—Ä—Ä–∏—Ç–∏–Ω)
- CA (–ö–∞–ª—å—Ü–∏–π)
- MG (–ú–∞–≥–Ω–∏–π)
- K (–ö–∞–ª–∏–π)
- NA (–ù–∞—Ç—Ä–∏–π)
- P (–§–æ—Å—Ñ–æ—Ä)
- ZN (–¶–∏–Ω–∫)

–í–ò–¢–ê–ú–ò–ù–´:
- B12 (–í–∏—Ç–∞–º–∏–Ω B12)
- FOLATE (–§–æ–ª–∏–µ–≤–∞—è –∫–∏—Å–ª–æ—Ç–∞)
- D3 (–í–∏—Ç–∞–º–∏–Ω D)

–ì–û–†–ú–û–ù–´ / –©–ò–¢–û–í–ò–î–ö–ê:
- TSH (–¢–¢–ì)
- T3 (–¢3 —Å–≤–æ–±–æ–¥–Ω—ã–π)
- T4 (–¢4 —Å–≤–æ–±–æ–¥–Ω—ã–π)
- FT3 (–¢3 —Å–≤–æ–±–æ–¥–Ω—ã–π)
- FT4 (–¢4 —Å–≤–æ–±–æ–¥–Ω—ã–π)

–ì–ï–ú–ê–¢–û–õ–û–ì–ò–Ø (–û–ë–©–ò–ô –ê–ù–ê–õ–ò–ó –ö–†–û–í–ò):
- RBC (–≠—Ä–∏—Ç—Ä–æ—Ü–∏—Ç—ã, —ç—Ä–∏—Ç—Ä, RBC, –∫—Ä–∞—Å–Ω—ã–µ –∫—Ä–æ–≤—è–Ω—ã–µ —Ç–µ–ª—å—Ü–∞)
- HGB (–ì–µ–º–æ–≥–ª–æ–±–∏–Ω, Hb, Hemoglobin)
- HCT (–ì–µ–º–∞—Ç–æ–∫—Ä–∏—Ç, Hematocrit)
- MCV (–°—Ä–µ–¥–Ω–∏–π –æ–±—ä–µ–º —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç–æ–≤, —Å—Ä–µ–¥–Ω–∏–π –æ–±—ä—ë–º —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç–∞)
- MCH (–°—Ä–µ–¥–Ω–µ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≥–µ–º–æ–≥–ª–æ–±–∏–Ω–∞ –≤ —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç–µ)
- MCHC (–°—Ä–µ–¥–Ω—è—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è Hb –≤ —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç–∞—Ö)
- RDW (–®–∏—Ä–∏–Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç–æ–≤, –æ—Ç–Ω.—à–∏—Ä–∏–Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥.)
- PLT (–¢—Ä–æ–º–±–æ—Ü–∏—Ç—ã, —Ç—Ä–æ–º–±, Platelets)
- MPV (–°—Ä–µ–¥–Ω–∏–π –æ–±—ä–µ–º —Ç—Ä–æ–º–±–æ—Ü–∏—Ç–æ–≤, —Å—Ä–µ–¥–Ω–∏–π –æ–±—ä—ë–º —Ç—Ä–æ–º–±–æ—Ü–∏—Ç–∞)
- PCT (–¢—Ä–æ–º–±–æ–∫—Ä–∏—Ç, Plateletcrit)
- PDW (–û—Ç–Ω–æ—Å–∏—Ç.—à–∏—Ä–∏–Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥.—Ç—Ä–æ–º–±–æ—Ü–∏—Ç–æ–≤, –æ—Ç–Ω.—à–∏—Ä–∏–Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥.—Ç—Ä–æ–º–±–æ—Ü–∏—Ç–æ–≤)
- WBC (–õ–µ–π–∫–æ—Ü–∏—Ç—ã, –ª–µ–π–∫, White Blood Cells)

‚ö†Ô∏è –í–ê–ñ–ù–û: –î–ª—è –ª–µ–π–∫–æ—Ü–∏—Ç–æ–≤ (NEU, LYM, MONO, EOS, BASO) –í–°–ï–ì–î–ê –∏–∑–≤–ª–µ–∫–∞–π –û–ë–ê –∑–Ω–∞—á–µ–Ω–∏—è –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å:
  1) –ê–ë–°–û–õ–Æ–¢–ù–û–ï –∑–Ω–∞—á–µ–Ω–∏–µ (–µ–¥–∏–Ω–∏—Ü–∞: 10*9/–ª –∏–ª–∏ 10^9/–ª)
  2) –ü–†–û–¶–ï–ù–¢–ù–û–ï –∑–Ω–∞—á–µ–Ω–∏–µ (–µ–¥–∏–Ω–∏—Ü–∞: %)
  
–≠—Ç–æ –û–¢–î–ï–õ–¨–ù–´–ï –±–∏–æ–º–∞—Ä–∫–µ—Ä—ã! –ù–∞–ø—Ä–∏–º–µ—Ä:
- NEU —Å unit="10*9/–ª" –∏ value=2.61
- NEU —Å unit="%" –∏ value=51.4

- NEU (–ù–µ–π—Ç—Ä–æ—Ñ–∏–ª—ã –∞–±—Å + %)
- LYM (–õ–∏–º—Ñ–æ—Ü–∏—Ç—ã –∞–±—Å + %)
- MONO (–ú–æ–Ω–æ—Ü–∏—Ç—ã –∞–±—Å + %)
- EOS (–≠–æ–∑–∏–Ω–æ—Ñ–∏–ª—ã –∞–±—Å + %)
- BASO (–ë–∞–∑–æ—Ñ–∏–ª—ã –∞–±—Å + %)
- ESR (–°–û–≠, —Å–∫–æ—Ä–æ—Å—Ç—å –æ—Å–µ–¥–∞–Ω–∏—è —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç–æ–≤)

–ü–û–õ–û–í–´–ï –ì–û–†–ú–û–ù–´ –ò –î–†.:
- TEST (–¢–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω –æ–±—â–∏–π/—Å–≤–æ–±–æ–¥–Ω—ã–π)
- SHBG (–ì–°–ü–ì, —Å–µ–∫—Å-—Å–≤—è–∑—ã–≤–∞—é—â–∏–π –≥–ª–æ–±—É–ª–∏–Ω)
- PROL (–ü—Ä–æ–ª–∞–∫—Ç–∏–Ω)
- FAI (–ò–Ω–¥–µ–∫—Å —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ —Ç–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω–∞, –ò–°–¢)
- E2 (–≠—Å—Ç—Ä–∞–¥–∏–æ–ª)
- PROG (–ü—Ä–æ–≥–µ—Å—Ç–µ—Ä–æ–Ω)
- LH (–õ–ì)
- FSH (–§–°–ì)
- CORT (–ö–æ—Ä—Ç–∏–∑–æ–ª)
- INS (–ò–Ω—Å—É–ª–∏–Ω)

–í–û–°–ü–ê–õ–ï–ù–ò–ï:
- CRP (–°-—Ä–µ–∞–∫—Ç–∏–≤–Ω—ã–π –±–µ–ª–æ–∫)

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –±–µ–∑ markdown-—Ä–∞–∑–º–µ—Ç–∫–∏."""

EXTRACTION_USER_PROMPT = """–ò–∑–≤–ª–µ–∫–∏ –±–∏–æ–º–∞—Ä–∫–µ—Ä—ã –∏–∑ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–æ–≤:

```
{ocr_text}
```

–í–µ—Ä–Ω–∏ JSON –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
{{
    "lab_name": "–Ω–∞–∑–≤–∞–Ω–∏–µ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –µ—Å—Ç—å",
    "analysis_date": "–¥–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD –µ—Å–ª–∏ –µ—Å—Ç—å",
    "biomarkers": [
        {{
            "code": "—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∫–æ–¥ (HGB, FE, TSH –∏ —Ç.–¥.)",
            "raw_name": "–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞",
            "value": —á–∏—Å–ª–æ–≤–æ–µ_–∑–Ω–∞—á–µ–Ω–∏–µ,
            "unit": "–µ–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è",
            "ref_min": –º–∏–Ω–∏–º—É–º_–Ω–æ—Ä–º—ã_–∏–ª–∏_null,
            "ref_max": –º–∞–∫—Å–∏–º—É–º_–Ω–æ—Ä–º—ã_–∏–ª–∏_null
        }}
    ]
}}

‚ö†Ô∏è –í–ê–ñ–ù–û: –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (ref_min, ref_max) –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π! 
–ü—Ä–∏–º–µ—Ä—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è:
- "RDW 13.6 % 12.0-13.6" ‚Üí ref_min=12.0, ref_max=13.6
- "–ì–µ–º–æ–≥–ª–æ–±–∏–Ω 154 –≥/–ª 135-169" ‚Üí ref_min=135, ref_max=169
- "PDW 16.3 % 10.1-16.1" ‚Üí ref_min=10.1, ref_max=16.1"""


SUMMARY_SYSTEM_PROMPT = """–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π –≤—Ä–∞—á-—Ç–µ—Ä–∞–ø–µ–≤—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –¥–∞—Ç—å –ü–ï–†–°–û–ù–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–£–Æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–æ–≤ —Å —É—á—ë—Ç–æ–º –ø—Ä–æ—Ñ–∏–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–∞.

–ü—Ä–∞–≤–∏–ª–∞:
1. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —É—á–∏—Ç—ã–≤–∞–π –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–∞ (—Ä–æ—Å—Ç, –≤–µ—Å, –≤–æ–∑—Ä–∞—Å—Ç, –ø–æ–ª, –∞–ª–ª–µ—Ä–≥–∏–∏, —Ö—Ä–æ–Ω–∏—á–µ—Å–∫–∏–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è)
2. –ü–∏—à–∏ –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º, –∏–∑–±–µ–≥–∞–π —Å–ª–æ–∂–Ω—ã—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
3. –°–Ω–∞—á–∞–ª–∞ —É–∫–∞–∂–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –≤–Ω–µ –Ω–æ—Ä–º—ã
4. –û–±—ä—è—Å–Ω–∏, —á—Ç–æ –º–æ–≥—É—Ç –æ–∑–Ω–∞—á–∞—Ç—å –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –ò–ú–ï–ù–ù–û –î–õ–Ø –≠–¢–û–ì–û –ü–ê–¶–ò–ï–ù–¢–ê
5. –£—á–∏—Ç—ã–≤–∞–π –≤–∑–∞–∏–º–æ—Å–≤—è–∑—å –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π —Å —Ö—Ä–æ–Ω–∏—á–µ—Å–∫–∏–º–∏ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è–º–∏ –ø–∞—Ü–∏–µ–Ω—Ç–∞
6. –ï—Å–ª–∏ –µ—Å—Ç—å –∞–ª–ª–µ—Ä–≥–∏–∏ ‚Äî —É—á–∏—Ç—ã–≤–∞–π –∏—Ö –ø—Ä–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö
7. –î–∞–π –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–±—Ä–∞–∑—É –∂–∏–∑–Ω–∏
8. –ù–∞–ø–æ–º–Ω–∏, —á—Ç–æ –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é –¥–æ–ª–∂–µ–Ω –¥–∞–≤–∞—Ç—å –≤—Ä–∞—á

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
- –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ (‚úÖ –Ω–æ—Ä–º–∞, ‚ö†Ô∏è –≤–Ω–∏–º–∞–Ω–∏–µ, ‚ùå –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ)
- –ù–∞—á–Ω–∏ —Å –∫—Ä–∞—Ç–∫–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–∞
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º
- –ë—É–¥—å –ª–∞–∫–æ–Ω–∏—á–µ–Ω –Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–µ–Ω"""


class AIParserService:
    """
    Service for AI-powered analysis of medical documents.
    Extracts structured biomarker data and generates interpretations.
    """
    
    def __init__(self):
        """Initialize the AI parser service."""
        # OpenRouter requires extra headers
        self.client = AsyncOpenAI(
            api_key=settings.openai_api_key,
            base_url=settings.openai_base_url,
            default_headers={
                "HTTP-Referer": "https://healthtracker.app",
                "X-Title": "Health Tracker Medical Analysis",
            }
        )
        self.model = settings.openai_model
        # Vision model - same as main model (gpt-4o-mini supports vision)
        self.vision_model = settings.openai_model
    
    async def extract_biomarkers_from_image(
        self,
        image_base64: str,
        content_type: str = "image/jpeg",
    ) -> Dict[str, Any]:
        """
        Extract biomarkers directly from image using GPT-4 Vision.
        Better for handwritten or low-quality scans.
        
        Args:
            image_base64: Base64 encoded image
            content_type: MIME type of the image
            
        Returns:
            Dictionary with extracted biomarkers
        """
        if not settings.openai_api_key:
            logger.warning("OpenAI API key not configured")
            return {"lab_name": None, "analysis_date": None, "biomarkers": []}
        
        try:
            logger.info("Using Vision API to extract biomarkers from image")
            
            response = await self.client.chat.completions.create(
                model=self.vision_model,
                messages=[
                    {"role": "system", "content": EXTRACTION_SYSTEM_PROMPT},
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": """–ò–∑–≤–ª–µ–∫–∏ –í–°–ï –±–∏–æ–º–∞—Ä–∫–µ—Ä—ã –∏–∑ —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ –∫—Ä–æ–≤–∏.
                                
–í–ê–ñ–ù–û: –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–π –í–°–ï –∑–Ω–∞—á–µ–Ω–∏—è, –≤–∫–ª—é—á–∞—è —Ä—É–∫–æ–ø–∏—Å–Ω—ã–µ!

–í–µ—Ä–Ω–∏ JSON:
{
    "lab_name": "–Ω–∞–∑–≤–∞–Ω–∏–µ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –µ—Å—Ç—å",
    "analysis_date": "–¥–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD –µ—Å–ª–∏ –µ—Å—Ç—å",
    "biomarkers": [
        {"code": "HGB", "raw_name": "–ì–µ–º–æ–≥–ª–æ–±–∏–Ω", "value": 132, "unit": "–≥/–ª", "ref_min": 80, "ref_max": 150}
    ]
}"""
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:{content_type};base64,{image_base64}",
                                    "detail": "high"
                                }
                            }
                        ]
                    },
                ],
                temperature=0.1,
                max_tokens=4000,
                response_format={"type": "json_object"},
            )
            
            result_text = response.choices[0].message.content
            
            # Try to extract JSON from response
            import re
            json_match = re.search(r'\{[\s\S]*\}', result_text)
            if json_match:
                result = json.loads(json_match.group())
            else:
                result = json.loads(result_text)
            
            result = self._validate_extraction(result)
            
            logger.info(f"Vision extraction completed: {len(result.get('biomarkers', []))} biomarkers found")
            
            return result
            
        except Exception as e:
            logger.error(f"Vision extraction failed: {e}")
            return {"lab_name": None, "analysis_date": None, "biomarkers": []}
    
    async def extract_biomarkers(
        self,
        ocr_text: str,
        lab_provider: Optional[LabProvider] = None,
    ) -> Dict[str, Any]:
        """
        Extract biomarkers from OCR text using GPT.
        
        Args:
            ocr_text: Raw text from OCR
            lab_provider: Known lab provider for better parsing
            
        Returns:
            Dictionary with extracted data:
            {
                "lab_name": str,
                "analysis_date": str,
                "biomarkers": List[Dict]
            }
        """
        if not settings.openai_api_key:
            logger.warning("OpenAI API key not configured, using fallback parser")
            return self._fallback_parse(ocr_text)
        
        try:
            # Add lab context if known
            context = ""
            if lab_provider:
                context = f"\n\n–ò–∑–≤–µ—Å—Ç–Ω–æ, —á—Ç–æ —ç—Ç–æ –∞–Ω–∞–ª–∏–∑ –∏–∑ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏: {lab_provider.value}"
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": EXTRACTION_SYSTEM_PROMPT},
                    {
                        "role": "user",
                        "content": EXTRACTION_USER_PROMPT.format(
                            ocr_text=ocr_text[:8000]  # Limit text length
                        ) + context
                    },
                ],
                temperature=0.1,  # Low temperature for consistent extraction
                max_tokens=4000,
                response_format={"type": "json_object"},
            )
            
            result_text = response.choices[0].message.content
            result = json.loads(result_text)
            
            # Validate and clean results
            result = self._validate_extraction(result)
            
            # Safety net: try to find missing critical biomarkers via regex
            result = self._enrich_with_regex(result, ocr_text)
            
            logger.info(
                f"AI extraction completed: {len(result.get('biomarkers', []))} biomarkers found"
            )
            
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse AI response as JSON: {e}")
            return self._fallback_parse(ocr_text)
        except Exception as e:
            logger.error(f"AI extraction failed: {e}")
            return self._fallback_parse(ocr_text)
    
    async def generate_summary(
        self,
        biomarkers: List[Dict[str, Any]],
        user_gender: Optional[str] = None,
        user_age: Optional[int] = None,
        patient_profile: Optional[Dict[str, Any]] = None,
    ) -> str:
        """
        Generate a human-readable summary of analysis results.
        
        Args:
            biomarkers: List of biomarker data with status
            user_gender: User's gender for context
            user_age: User's age for context
            patient_profile: Full patient profile data
            
        Returns:
            Human-readable summary text
        """
        if not settings.openai_api_key:
            return self._generate_simple_summary(biomarkers)
        
        try:
            # Prepare biomarker data for prompt
            biomarker_text = self._format_biomarkers_for_prompt(biomarkers)
            
            # Build comprehensive patient context
            context = "\n\nüë§ **–ü–†–û–§–ò–õ–¨ –ü–ê–¶–ò–ï–ù–¢–ê:**"
            
            if user_gender:
                context += f"\n- –ü–æ–ª: {'–º—É–∂—á–∏–Ω–∞' if user_gender == 'male' else '–∂–µ–Ω—â–∏–Ω–∞'}"
            if user_age:
                context += f"\n- –í–æ–∑—Ä–∞—Å—Ç: {user_age} –ª–µ—Ç"
            
            if patient_profile:
                # Body parameters (height, weight, waist)
                body = patient_profile.get("body_parameters", {})
                if body:
                    if body.get("height"):
                        context += f"\n- –†–æ—Å—Ç: {body['height']} —Å–º"
                    if body.get("weight"):
                        context += f"\n- –í–µ—Å: {body['weight']} –∫–≥"
                    if body.get("waist"):
                        context += f"\n- –û–±—Ö–≤–∞—Ç —Ç–∞–ª–∏–∏: {body['waist']} —Å–º"
                    # Calculate BMI if possible
                    if body.get("height") and body.get("weight"):
                        height_m = float(body["height"]) / 100
                        bmi = float(body["weight"]) / (height_m * height_m)
                        context += f"\n- –ò–ú–¢: {bmi:.1f}"
                
                # Allergies
                allergies = patient_profile.get("allergies", [])
                if allergies:
                    context += f"\n- ‚ö†Ô∏è –ê–ª–ª–µ—Ä–≥–∏–∏: {', '.join(allergies)}"
                
                # Chronic diseases
                chronic = patient_profile.get("chronic_diseases", [])
                if chronic:
                    context += f"\n- üè• –•—Ä–æ–Ω–∏—á–µ—Å–∫–∏–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è: {', '.join(chronic)}"
                
                # Hereditary diseases
                hereditary = patient_profile.get("hereditary_diseases", [])
                if hereditary:
                    context += f"\n- üß¨ –ù–∞—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è: {', '.join(hereditary)}"
                
                # Lifestyle
                lifestyle = patient_profile.get("lifestyle", {})
                if lifestyle:
                    context += f"\n- –û–±—Ä–∞–∑ –∂–∏–∑–Ω–∏: {json.dumps(lifestyle, ensure_ascii=False)}"
            
            prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–æ–≤ —Å —É—á—ë—Ç–æ–º –ø—Ä–æ—Ñ–∏–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–∞.
{context}

üìä **–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–û–í:**
{biomarker_text}

–î–∞–π –ü–ï–†–°–û–ù–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–£–Æ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É, —É—á–∏—Ç—ã–≤–∞—è –≤—Å–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –ø–∞—Ü–∏–µ–Ω—Ç–∞."""
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": SUMMARY_SYSTEM_PROMPT},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.7,
                max_tokens=2000,
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Summary generation failed: {e}")
            return self._generate_simple_summary(biomarkers)
    
    async def generate_search_keywords(
        self,
        biomarkers: List[Dict[str, Any]],
        patient_profile: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, List[str]]:
        """
        Generate search keywords for finding products based on analysis.
        
        Returns:
            Dict where key is biomarker code (or 'general') and value is list of keywords.
        """
        if not settings.openai_api_key:
            return {}
        
        try:
            # Filter problem biomarkers
            problem_biomarkers = [
                b for b in biomarkers
                if b.get("status") in ("low", "high", "critical_low", "critical_high")
            ]
            
            if not problem_biomarkers:
                return {}
            
            biomarker_text = self._format_biomarkers_for_prompt(problem_biomarkers)
            
            profile_text = ""
            if patient_profile:
                profile_text = f"\n–ü—Ä–æ—Ñ–∏–ª—å –ø–∞—Ü–∏–µ–Ω—Ç–∞: {json.dumps(patient_profile, ensure_ascii=False)}"
            
            prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –≤ –∞–Ω–∞–ª–∏–∑–∞—Ö –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ë–ê–î–æ–≤ –∏ —Ç–æ–≤–∞—Ä–æ–≤ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω–µ.
            
–û—Ç–∫–ª–æ–Ω–µ–Ω–∏—è:
{biomarker_text}
{profile_text}

–í–µ—Ä–Ω–∏ JSON:
{{
    "biomarker_keywords": {{
        "CODE": ["keyword1", "keyword2"]
    }},
    "general_keywords": ["keyword3", "keyword4"]
}}
"""
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system", 
                        "content": "–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –ø–æ–∏—Å–∫—É –ë–ê–î–æ–≤. –ì–µ–Ω–µ—Ä–∏—Ä—É–π —Ç–æ—á–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä: '–ñ–µ–ª–µ–∑–æ —Ö–µ–ª–∞—Ç', '–í–∏—Ç–∞–º–∏–Ω D3', '–û–º–µ–≥–∞-3')."
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.3,
                response_format={"type": "json_object"},
            )
            
            result = json.loads(response.choices[0].message.content)
            return result
            
        except Exception as e:
            logger.error(f"Keyword generation failed: {e}")
            return {}

    async def generate_recommendations(
        self,
        biomarkers: List[Dict[str, Any]],
        available_products: List[Dict[str, Any]],
    ) -> List[Dict[str, Any]]:
        """
        Generate product recommendations based on biomarker deficiencies.
        
        Args:
            biomarkers: List of biomarkers with status
            available_products: List of products from catalog
            
        Returns:
            List of recommendations with reasons
        """
        if not settings.openai_api_key or not available_products:
            return self._fallback_recommendations(biomarkers, available_products)
        
        try:
            # Filter biomarkers that need attention
            problem_biomarkers = [
                b for b in biomarkers
                if b.get("status") in ("low", "high", "critical_low", "critical_high")
            ]
            
            if not problem_biomarkers:
                return []
            
            # Prepare data for prompt
            biomarker_text = self._format_biomarkers_for_prompt(problem_biomarkers)
            products_text = self._format_products_for_prompt(available_products[:50])
            
            prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π –≤ –∞–Ω–∞–ª–∏–∑–∞—Ö –ø–æ–¥–±–µ—Ä–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–æ–±–∞–≤–∫–∏ –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞.

–û—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –≤ –∞–Ω–∞–ª–∏–∑–∞—Ö:
{biomarker_text}

–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã:
{products_text}

–í–µ—Ä–Ω–∏ JSON:
{{
    "recommendations": [
        {{
            "product_id": id_—Ç–æ–≤–∞—Ä–∞,
            "biomarker_code": "–∫–æ–¥_–±–∏–æ–º–∞—Ä–∫–µ—Ä–∞",
            "reason": "–ø–æ—á–µ–º—É —ç—Ç–æ—Ç —Ç–æ–≤–∞—Ä –ø–æ–º–æ–∂–µ—Ç",
            "priority": 1-5,
            "confidence": 0.0-1.0
        }}
    ]
}}"""
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "–¢—ã ‚Äî –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –ø–æ–¥–±–æ—Ä—É –ë–ê–î–æ–≤. –†–µ–∫–æ–º–µ–Ω–¥—É–π —Ç–æ–ª—å–∫–æ —Ç–µ —Ç–æ–≤–∞—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–ª—å–Ω–æ –º–æ–≥—É—Ç –ø–æ–º–æ—á—å —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –¥–µ—Ñ–∏—Ü–∏—Ç–∞–º–∏. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON."
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.3,
                max_tokens=2000,
                response_format={"type": "json_object"},
            )
            
            result = json.loads(response.choices[0].message.content)
            return result.get("recommendations", [])
            
        except Exception as e:
            logger.error(f"Recommendation generation failed: {e}")
            return self._fallback_recommendations(biomarkers, available_products)
    
    def _validate_extraction(self, result: Dict) -> Dict:
        """Validate and clean extracted data."""
        validated = {
            "lab_name": result.get("lab_name"),
            "analysis_date": result.get("analysis_date"),
            "biomarkers": [],
        }
        
        # Track (code, unit) pairs to allow both absolute and percentage values
        seen_combinations = set()
        
        for bio in result.get("biomarkers", []):
            # Skip invalid entries
            if not bio.get("code") or bio.get("value") is None:
                continue
            
            try:
                value = float(bio["value"])
            except (ValueError, TypeError):
                continue
            
            # Normalize code from AI output to ensure standard codes
            raw_code = bio.get("code", "")
            code = self._normalize_biomarker_code(raw_code)
            
            # Fallback –¥–ª—è unit –µ—Å–ª–∏ AI –Ω–µ –Ω–∞—à—ë–ª
            unit = bio.get("unit") or "–µ–¥."
            if not unit.strip():
                unit = "–µ–¥."
            
            # Skip duplicates (same code AND same unit)
            combination = (code, unit)
            if combination in seen_combinations:
                logger.info(f"Duplicate biomarker skipped: {code} ({unit})")
                continue
            seen_combinations.add(combination)
            
            # Get reference ranges
            ref_min = self._safe_float(bio.get("ref_min"))
            ref_max = self._safe_float(bio.get("ref_max"))
            
            # Fix decimal point if needed (e.g., 922 -> 92.2 for MCV)
            value = self._fix_decimal_point(code, value, ref_min, ref_max)
            
            ref_text = f", ref=[{ref_min}-{ref_max}]" if ref_min and ref_max else ", ref=None"
            logger.info(f"Biomarker processing: raw='{raw_code}', normalized='{code}', value={value}, unit='{unit}'{ref_text}")
            
            validated["biomarkers"].append({
                "code": code,
                "raw_name": bio.get("raw_name", ""),
                "value": value,
                "unit": unit,
                "ref_min": ref_min,
                "ref_max": ref_max,
            })
        
        return validated
    
    def _safe_float(self, value: Any) -> Optional[float]:
        """Safely convert value to float."""
        if value is None:
            return None
        try:
            return float(value)
        except (ValueError, TypeError):
            return None
    
    def _fix_decimal_point(self, code: str, value: float, ref_min: Optional[float], ref_max: Optional[float]) -> float:
        """Fix missing decimal point based on reference ranges."""
        # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –¥–ª—è –æ–±—â–∏—Ö –±–∏–æ–º–∞—Ä–∫–µ—Ä–æ–≤
        known_ranges = {
            "MCV": (80, 100),      # –°—Ä–µ–¥–Ω–∏–π –æ–±—ä–µ–º —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç–æ–≤ (—Ñ–ª)
            "MCH": (27, 35),       # –°—Ä–µ–¥–Ω–µ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ Hb –≤ —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç–µ (–ø–≥)
            "MCHC": (32, 36),      # –°—Ä–µ–¥–Ω—è—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è Hb (–≥/–¥–ª)
            "MPV": (7, 12),        # –°—Ä–µ–¥–Ω–∏–π –æ–±—ä–µ–º —Ç—Ä–æ–º–±–æ—Ü–∏—Ç–æ–≤ (—Ñ–ª)
            "HGB": (120, 180),     # –ì–µ–º–æ–≥–ª–æ–±–∏–Ω (–≥/–ª)
            "RBC": (4.0, 5.5),     # –≠—Ä–∏—Ç—Ä–æ—Ü–∏—Ç—ã (10^12/–ª)
            "WBC": (4.0, 9.0),     # –õ–µ–π–∫–æ—Ü–∏—Ç—ã (10^9/–ª)
            "PLT": (150, 400),     # –¢—Ä–æ–º–±–æ—Ü–∏—Ç—ã (10^9/–ª)
            "HCT": (36, 50),       # –ì–µ–º–∞—Ç–æ–∫—Ä–∏—Ç (%)
            "RDW": (11, 15),       # –®–∏—Ä–∏–Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç–æ–≤ (%)
            "PCT": (0.15, 0.40),   # –¢—Ä–æ–º–±–æ–∫—Ä–∏—Ç (%)
            "PDW": (10, 18),       # –®–∏—Ä–∏–Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç—Ä–æ–º–±–æ—Ü–∏—Ç–æ–≤ (%)
            "NEU": (2.0, 7.0),     # –ù–µ–π—Ç—Ä–æ—Ñ–∏–ª—ã –∞–±—Å (10^9/–ª)
            "LYM": (1.0, 4.0),     # –õ–∏–º—Ñ–æ—Ü–∏—Ç—ã –∞–±—Å (10^9/–ª)
            "MONO": (0.2, 0.8),    # –ú–æ–Ω–æ—Ü–∏—Ç—ã –∞–±—Å (10^9/–ª)
            "EOS": (0.02, 0.5),    # –≠–æ–∑–∏–Ω–æ—Ñ–∏–ª—ã –∞–±—Å (10^9/–ª)
            "BASO": (0.0, 0.1),    # –ë–∞–∑–æ—Ñ–∏–ª—ã –∞–±—Å (10^9/–ª)
            "ESR": (0, 20),        # –°–û–≠ (–º–º/—á–∞—Å)
        }
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å
        if ref_min is not None and ref_max is not None:
            expected_min = ref_min
            expected_max = ref_max
        elif code in known_ranges:
            expected_min, expected_max = known_ranges[code]
        else:
            # –ù–µ –∑–Ω–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
            return value
        
        # –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ (–≤ 10+ —Ä–∞–∑ –±–æ–ª—å—à–µ –º–∞–∫—Å)
        if value > expected_max * 10:
            # –ü—Ä–æ–±—É–µ–º –≤—Å—Ç–∞–≤–∏—Ç—å —Ç–æ—á–∫—É –ø–µ—Ä–µ–¥ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ü–∏—Ñ—Ä–æ–π
            # –ù–∞–ø—Ä–∏–º–µ—Ä: 922 -> 92.2, 1540 -> 154.0
            value_str = str(int(value))
            if len(value_str) >= 2:
                fixed_str = value_str[:-1] + "." + value_str[-1]
                fixed_value = float(fixed_str)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
                if expected_min <= fixed_value <= expected_max * 1.5:
                    logger.info(f"[Decimal Fix] {code}: {value} -> {fixed_value} (ref: {expected_min}-{expected_max})")
                    return fixed_value
        
        return value
    
    def _enrich_with_regex(self, result: Dict, ocr_text: str) -> Dict:
        """Find missing critical biomarkers using regex."""
        logger.info(f"[Regex Rescue] Starting with {len(result.get('biomarkers', []))} biomarkers")
        logger.info(f"[Regex Rescue] OCR text preview (first 300 chars): {ocr_text[:300]}")
        logger.info(f"[Regex Rescue] FULL OCR text for debugging:\n{ocr_text}")
        
        existing_codes = {b["code"] for b in result.get("biomarkers", [])}
        logger.info(f"[Regex Rescue] Existing codes: {existing_codes}")
        
        # Regex patterns for critical hormones that AI might miss
        critical_patterns = {
            "TSH": [
                r"(?:–¢–¢–ì|TSH|–¢–∏—Ä–µ–æ—Ç—Ä–æ–ø–Ω—ã–π)[^:\d]*[:\s]*([\d.,]+)",
            ],
            "FT4": [
                r"(?:–¢4\s*—Å–≤–æ–±|FT4|T4\s*free)[^:\d]*[:\s]*([\d.,]+)",
            ],
            "TEST": [
                r"(?:–¢–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω|Testosterone)[^:\d]*[:\s]*([\d.,]+)",
            ],
            "SHBG": [
                r"(?:–ì–°–ü–ì|SHBG|Sex\s*hormone)[^:\d]*[:\s]*([\d.,]+)",
            ],
            "PROL": [
                r"(?:–ü—Ä–æ–ª–∞–∫—Ç–∏–Ω|Prolactin)[^:\d]*[:\s]*([\d.,]+)",
            ],
            "FAI": [
                r"(?:–ò–°–¢|FAI|Index of Free Testosterone|–ò–Ω–¥–µ–∫—Å —Å–≤–æ–±\. —Ç–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω–∞)[^:\d]*[:\s]*([\d.,]+)",
            ],
            "RDW": [
                r"(?:RDW|–®–∏—Ä–∏–Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª|–û—Ç–Ω.*—à–∏—Ä–∏–Ω–∞.*—ç—Ä–∏—Ç—Ä–æ—Ü)[^:\d]*[:\s]*([\d.,]+)",
            ],
            "PDW": [
                r"(?:PDW|–û—Ç–Ω–æ—Å–∏—Ç.*—à–∏—Ä–∏–Ω–∞.*—Ç—Ä–æ–º–±–æ—Ü–∏—Ç|–æ—Ç–Ω.*—à–∏—Ä–∏–Ω–∞.*—Ç—Ä–æ–º–±)[^:\d]*[:\s]*([\d.,]+)",
            ]
        }
        
        for code, patterns in critical_patterns.items():
            if code in existing_codes:
                logger.info(f"[Regex Rescue] Skipping {code} (already exists)")
                continue
            
            logger.info(f"[Regex Rescue] Searching for missing {code}...")
            for pattern in patterns:
                match = re.search(pattern, ocr_text, re.IGNORECASE)
                if match:
                    try:
                        value_str = match.group(1).replace(",", ".")
                        # Clean value string from possible artifacts like trailing dots
                        value_str = value_str.rstrip(".")
                        value = float(value_str)
                        
                        logger.info(f"[Regex Rescue] ‚úÖ Found missing {code} = {value}")
                        
                        result["biomarkers"].append({
                            "code": code,
                            "raw_name": "Rescued by Regex",
                            "value": value,
                            "unit": "–µ–¥.",  # Fallback unit for regex rescue
                            "ref_min": None,
                            "ref_max": None
                        })
                        existing_codes.add(code)
                        break
                    except ValueError as e:
                        logger.info(f"[Regex Rescue] ValueError for {code}: {e}")
                        continue
                else:
                    logger.info(f"[Regex Rescue] ‚ùå Pattern didn't match for {code}")
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è RDW-SD (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ —Å –æ—Ç–º–µ—Ç–∫–æ–π +)
        # –ù—É–∂–µ–Ω –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞–¥ RDW-CV (–∫–æ—ç—Ñ—Ñ. –≤–∞—Ä–∏–∞—Ü–∏–∏)
        logger.info("[Regex Rescue] Checking for RDW-SD (standard deviation)...")
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω —Å —É—á—ë—Ç–æ–º –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫ –∏ –ø—Ä–æ–±–µ–ª–æ–≤
        rdw_sd_pattern = r"(?:–û—Ç–Ω[.\s]*—à–∏—Ä–∏–Ω–∞[.\s]*—Ä–∞—Å–ø—Ä–µ–¥[.\s]*—ç—Ä–∏—Ç—Ä[.\s]*–ø–æ[.\s]*–æ–±—ä–µ–º[^\d]*—Å—Ç[.\s]*–æ—Ç–∫–ª|RDW[.\s]*SD)[^\d]*([\d.,]+)\s*\+?\s*(?:—Ñ–ª|fl)\s*([\d.,]+)-([\d.,]+)"
        logger.info(f"[Regex Rescue] RDW-SD pattern: {rdw_sd_pattern}")
        rdw_sd_match = re.search(rdw_sd_pattern, ocr_text, re.IGNORECASE | re.DOTALL)
        
        if rdw_sd_match:
            try:
                value_str = rdw_sd_match.group(1).replace(",", ".").rstrip(".")
                ref_min_str = rdw_sd_match.group(2).replace(",", ".").rstrip(".")
                ref_max_str = rdw_sd_match.group(3).replace(",", ".").rstrip(".")
                value = float(value_str)
                ref_min = float(ref_min_str)
                ref_max = float(ref_max_str)
                
                logger.info(f"[Regex Rescue] ‚úÖ Found RDW-SD = {value} —Ñ–ª, ref=[{ref_min}-{ref_max}]")
                
                # –ó–∞–º–µ–Ω—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π RDW –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å –∏ —ç—Ç–æ CV (%)
                replaced = False
                for i, bm in enumerate(result.get("biomarkers", [])):
                    if bm.get("code") == "RDW" and bm.get("unit") == "%":
                        # –≠—Ç–æ RDW-CV, –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ RDW-SD
                        result["biomarkers"][i] = {
                            "code": "RDW",
                            "raw_name": "RDW-SD (—Å—Ç.–æ—Ç–∫–ª.)",
                            "value": value,
                            "unit": "—Ñ–ª",
                            "ref_min": ref_min,
                            "ref_max": ref_max
                        }
                        replaced = True
                        logger.info(f"[Regex Rescue] ‚úÖ Replaced RDW-CV with RDW-SD")
                        break
                
                if not replaced and "RDW" not in existing_codes:
                    result["biomarkers"].append({
                        "code": "RDW",
                        "raw_name": "RDW-SD (—Å—Ç.–æ—Ç–∫–ª.)",
                        "value": value,
                        "unit": "—Ñ–ª",
                        "ref_min": ref_min,
                        "ref_max": ref_max
                    })
                    existing_codes.add("RDW")
                    logger.info(f"[Regex Rescue] ‚úÖ Added RDW-SD")
            except (ValueError, IndexError) as e:
                logger.info(f"[Regex Rescue] Error parsing RDW-SD: {e}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ª–µ–π–∫–æ—Ü–∏—Ç–æ–≤ (–µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç)
        logger.info("[Regex Rescue] Searching for percentage values of WBC...")
        
        leukocyte_percentage_patterns = {
            "NEU": [
                r"(?:–ù–µ–π—Ç—Ä–æ—Ñ–∏–ª|Neutrophil|NEUT)[^\d]*(\d+[.,]\d+)\s*%\s*([\d.,]+)-([\d.,]+)",
                r"(?:–ù–µ–π—Ç—Ä–æ—Ñ–∏–ª|Neutrophil|NEUT)[^\d]*(\d+[.,]\d+)\s*%",
            ],
            "LYM": [
                r"(?:–õ–∏–º—Ñ–æ—Ü–∏—Ç|Lymphocyte|LYMPH|LYM)[^\d]*(\d+[.,]\d+)\s*%\s*([\d.,]+)-([\d.,]+)",
                r"(?:–õ–∏–º—Ñ–æ—Ü–∏—Ç|Lymphocyte|LYMPH|LYM)[^\d]*(\d+[.,]\d+)\s*%",
            ],
            "MONO": [
                r"(?:–ú–æ–Ω–æ—Ü–∏—Ç|Monocyte|MONO)[^\d]*(\d+[.,]\d+)\s*%\s*([\d.,]+)-([\d.,]+)",
                r"(?:–ú–æ–Ω–æ—Ü–∏—Ç|Monocyte|MONO)[^\d]*(\d+[.,]\d+)\s*%",
            ],
            "EOS": [
                r"(?:–≠–æ–∑–∏–Ω–æ—Ñ–∏–ª|Eosinophil|EOS)[^\d]*(\d+[.,]\d+)\s*%\s*([\d.,]+)-([\d.,]+)",
                r"(?:–≠–æ–∑–∏–Ω–æ—Ñ–∏–ª|Eosinophil|EOS)[^\d]*(\d+[.,]\d+)\s*%",
            ],
            "BASO": [
                r"(?:–ë–∞–∑–æ—Ñ–∏–ª|Basophil|BASO)[^\d]*(\d+[.,]\d+)\s*%\s*([\d.,]+)-([\d.,]+)",
                r"(?:–ë–∞–∑–æ—Ñ–∏–ª|Basophil|BASO)[^\d]*(\d+[.,]\d+)\s*%",
            ],
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ –∏–∑ –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —É–∂–µ –µ—Å—Ç—å
        existing_percentage_codes = set()
        existing_percentage_without_refs = []  # (index, code) –¥–ª—è –±–∏–æ–º–∞—Ä–∫–µ—Ä–æ–≤ –±–µ–∑ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–≤
        
        for i, bm in enumerate(result.get("biomarkers", [])):
            if bm.get("unit") == "%" and bm.get("code") in leukocyte_percentage_patterns:
                existing_percentage_codes.add(bm["code"])
                if not bm.get("ref_min") or not bm.get("ref_max"):
                    existing_percentage_without_refs.append((i, bm["code"]))
        
        for code, patterns in leukocyte_percentage_patterns.items():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–∏—Ç—å —Ä–µ—Ñ–µ—Ä–µ–Ω—Å—ã –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –±–∏–æ–º–∞—Ä–∫–µ—Ä–∞
            needs_update_index = None
            for idx, existing_code in existing_percentage_without_refs:
                if existing_code == code:
                    needs_update_index = idx
                    break
            
            if code in existing_percentage_codes and needs_update_index is None:
                logger.info(f"[Regex Rescue] {code}% already exists with refs")
                continue
            
            for idx, pattern in enumerate(patterns):
                logger.info(f"[Regex Rescue] Trying {code}% pattern #{idx+1}: {pattern[:50]}...")
                matches = re.findall(pattern, ocr_text, re.IGNORECASE)
                logger.info(f"[Regex Rescue] {code}% pattern #{idx+1} found {len(matches)} matches")
                if matches:
                    try:
                        # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (–æ–±—ã—á–Ω–æ –ø—Ä–æ—Ü–µ–Ω—Ç –∏–¥—ë—Ç –ø–æ—Å–ª–µ –∞–±—Å)
                        match = matches[-1]
                        
                        # –ï—Å–ª–∏ match tuple —Å (value, ref_min, ref_max)
                        if isinstance(match, tuple) and len(match) >= 3:
                            value_str = match[0].replace(",", ".").rstrip(".")
                            ref_min_str = match[1].replace(",", ".").rstrip(".")
                            ref_max_str = match[2].replace(",", ".").rstrip(".")
                            value = float(value_str)
                            ref_min = float(ref_min_str)
                            ref_max = float(ref_max_str)
                        elif isinstance(match, tuple):
                            value_str = match[0].replace(",", ".").rstrip(".")
                            value = float(value_str)
                            ref_min = None
                            ref_max = None
                        else:
                            value_str = match.replace(",", ".").rstrip(".")
                            value = float(value_str)
                            ref_min = None
                            ref_max = None
                        
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –ø—Ä–æ—Ü–µ–Ω—Ç (0-100)
                        if 0 <= value <= 100:
                            logger.info(f"[Regex Rescue] ‚úÖ Found {code}% = {value}, ref=[{ref_min}-{ref_max}]" if ref_min else f"[Regex Rescue] ‚úÖ Found {code}% = {value}")
                            
                            # –ï—Å–ª–∏ –±–∏–æ–º–∞—Ä–∫–µ—Ä —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –Ω–æ –±–µ–∑ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–≤ - –æ–±–Ω–æ–≤–ª—è–µ–º
                            if needs_update_index is not None:
                                result["biomarkers"][needs_update_index]["ref_min"] = ref_min
                                result["biomarkers"][needs_update_index]["ref_max"] = ref_max
                                logger.info(f"[Regex Rescue] ‚úÖ Updated {code}% references")
                            else:
                                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π
                                result["biomarkers"].append({
                                    "code": code,
                                    "raw_name": f"Rescued {code} %",
                                    "value": value,
                                    "unit": "%",
                                    "ref_min": ref_min,
                                    "ref_max": ref_max
                                })
                                existing_percentage_codes.add(code)
                            break
                    except (ValueError, IndexError) as e:
                        logger.info(f"[Regex Rescue] Error parsing {code}%: {e}")
                        continue
        
        logger.info(f"[Regex Rescue] Final count: {len(result.get('biomarkers', []))} biomarkers")
        return result

    def _fallback_parse(self, ocr_text: str) -> Dict:
        """
        Fallback regex-based parser when AI is unavailable.
        Handles common formats from Russian labs.
        """
        biomarkers = []
        
        # Common patterns for lab results
        patterns = [
            # "–ì–µ–º–æ–≥–ª–æ–±–∏–Ω: 140 –≥/–ª (120-160)"
            r"([–ê-–Ø–∞-—èA-Za-z\s]+):\s*([\d.,]+)\s*([–∞-—è–ê-–Øa-zA-Z/¬≥¬≤]+)?\s*(?:\(?([\d.,]+)\s*[-‚Äì]\s*([\d.,]+)\)?)?",
            # "HGB 140 g/L"
            r"([A-Z]{2,5})\s+([\d.,]+)\s*([–∞-—è–ê-–Øa-zA-Z/¬≥¬≤]+)?",
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, ocr_text)
            for match in matches:
                if len(match) >= 2:
                    name = match[0].strip()
                    try:
                        value = float(match[1].replace(",", "."))
                    except ValueError:
                        continue
                    
                    unit = match[2] if len(match) > 2 else ""
                    ref_min = self._safe_float(match[3]) if len(match) > 3 else None
                    ref_max = self._safe_float(match[4]) if len(match) > 4 else None
                    
                    # Try to normalize code
                    code = self._normalize_biomarker_code(name)
                    
                    biomarkers.append({
                        "code": code,
                        "raw_name": name,
                        "value": value,
                        "unit": unit,
                        "ref_min": ref_min,
                        "ref_max": ref_max,
                    })
        
        return {
            "lab_name": None,
            "analysis_date": None,
            "biomarkers": biomarkers,
        }
    
    def _normalize_biomarker_code(self, name: str) -> str:
        """Normalize biomarker name to standard code."""
        name_lower = name.lower().strip()
        
        # Exact matches for short codes (to avoid substring conflicts)
        exact_matches = {
            "mchc": "MCHC",
            "mch": "MCH",
            "mcv": "MCV",
            "mpv": "MPV",
            "rdw": "RDW",
            "pdw": "PDW",
            "pct": "PCT",
            "hct": "HCT",
            "wbc": "WBC",
            "rbc": "RBC",
            "plt": "PLT",
            "hgb": "HGB",
            "hb": "HGB",
            "neu": "NEU",
            "lym": "LYM",
            "mono": "MONO",
            "eos": "EOS",
            "baso": "BASO",
            "esr": "ESR",
        }
        
        # Check exact match first
        if name_lower in exact_matches:
            return exact_matches[name_lower]
        
        mappings = {
            # –ì–û–†–ú–û–ù–´ (–≤–∞–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –ø–µ—Ä–≤—ã–º–∏ –∏–∑-–∑–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –∏–º–µ–Ω)
            "–≥—Å–ø–≥": "SHBG",
            "shbg": "SHBG",
            "sex hormone": "SHBG",
            "–∏–Ω–¥–µ–∫—Å —Å–≤–æ–±": "FAI",
            "–∏—Å—Ç": "FAI",
            "fai": "FAI",
            "free androgen": "FAI",
            "—Ç–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω": "TEST",
            "testosterone": "TEST",
            "–ø—Ä–æ–ª–∞–∫—Ç–∏–Ω": "PROL",
            "prolactin": "PROL",
            "—Ç—Ç–≥": "TSH",
            "tsh": "TSH",
            "thyrotropin": "TSH",
            "—Ç–∏—Ä–µ–æ—Ç—Ä–æ–ø–Ω—ã–π": "TSH",
            "—Ç4": "FT4",
            "ft4": "FT4",
            "free t4": "FT4",
            "—Å–≤–æ–±–æ–¥–Ω—ã–π —Ç4": "FT4",
            "—Ç3": "FT3",
            "ft3": "FT3",
            "free t3": "FT3",

            # –ì–ï–ú–ê–¢–û–õ–û–ì–ò–Ø (–û–ë–©–ò–ô –ê–ù–ê–õ–ò–ó –ö–†–û–í–ò)
            "–≥–µ–º–æ–≥–ª–æ–±–∏–Ω": "HGB",
            "hemoglobin": "HGB",
            "hgb": "HGB",
            "hb": "HGB",
            "—ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç—ã": "RBC",
            "—ç—Ä–∏—Ç—Ä": "RBC",
            "rbc": "RBC",
            "–ª–µ–π–∫–æ—Ü–∏—Ç—ã": "WBC",
            "–ª–µ–π–∫": "WBC",
            "wbc": "WBC",
            "—Ç—Ä–æ–º–±–æ—Ü–∏—Ç—ã": "PLT",
            "—Ç—Ä–æ–º–±": "PLT",
            "platelets": "PLT",
            "plt": "PLT",
            "–≥–µ–º–∞—Ç–æ–∫—Ä–∏—Ç": "HCT",
            "hematocrit": "HCT",
            "hct": "HCT",
            "—Å—Ä–µ–¥–Ω–∏–π –æ–±—ä–µ–º —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç": "MCV",
            "—Å—Ä–µ–¥–Ω–∏–π –æ–±—ä—ë–º —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç": "MCV",
            "mcv": "MCV",
            # –í–ê–ñ–ù–û: MCHC –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –†–ê–ù–¨–®–ï MCH (–ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥—Å—Ç—Ä–æ–∫)
            "—Å—Ä–µ–¥–Ω—è—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è hb": "MCHC",
            "—Å—Ä–µ–¥–Ω—è—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è –≥–µ–º–æ–≥–ª–æ–±–∏–Ω–∞": "MCHC",
            "—Å—Ä–µ–¥–Ω—è—è –∫–æ–Ω—Ü": "MCHC",
            "mchc": "MCHC",
            "—Å—Ä–µ–¥–Ω–µ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≥–µ–º–æ–≥–ª–æ–±–∏–Ω–∞ –≤ —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç–µ": "MCH",
            "—Å—Ä–µ–¥–Ω–µ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ hb": "MCH",
            "—Å—Ä–µ–¥–Ω–µ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ hemoglobin": "MCH",
            "mch": "MCH",
            "—à–∏—Ä–∏–Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç": "RDW",
            "–æ—Ç–Ω.—à–∏—Ä–∏–Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥.—ç—Ä–∏—Ç—Ä": "RDW",
            "rdw": "RDW",
            "—Å—Ä–µ–¥–Ω–∏–π –æ–±—ä–µ–º —Ç—Ä–æ–º–±–æ—Ü–∏—Ç": "MPV",
            "—Å—Ä–µ–¥–Ω–∏–π –æ–±—ä—ë–º —Ç—Ä–æ–º–±–æ—Ü–∏—Ç": "MPV",
            "mpv": "MPV",
            "—Ç—Ä–æ–º–±–æ–∫—Ä–∏—Ç": "PCT",
            "pct": "PCT",
            "–æ—Ç–Ω–æ—Å–∏—Ç.—à–∏—Ä–∏–Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥.—Ç—Ä–æ–º–±–æ—Ü–∏—Ç": "PDW",
            "–æ—Ç–Ω.—à–∏—Ä–∏–Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥.—Ç—Ä–æ–º–±": "PDW",
            "pdw": "PDW",
            "–Ω–µ–π—Ç—Ä–æ—Ñ–∏–ª—ã": "NEU",
            "neutrophils": "NEU",
            "neu": "NEU",
            "–ª–∏–º—Ñ–æ—Ü–∏—Ç—ã": "LYM",
            "lymphocytes": "LYM",
            "lym": "LYM",
            "–º–æ–Ω–æ—Ü–∏—Ç—ã": "MONO",
            "monocytes": "MONO",
            "mono": "MONO",
            "—ç–æ–∑–∏–Ω–æ—Ñ–∏–ª—ã": "EOS",
            "eosinophils": "EOS",
            "eos": "EOS",
            "–±–∞–∑–æ—Ñ–∏–ª—ã": "BASO",
            "basophils": "BASO",
            "baso": "BASO",
            "—Å–æ—ç": "ESR",
            "esr": "ESR",
            "–≥–ª—é–∫–æ–∑–∞": "GLU",
            "glucose": "GLU",
            "—Ö–æ–ª–µ—Å—Ç–µ—Ä–∏–Ω": "CHOL",
            "cholesterol": "CHOL",
            "–∞–ª—Ç": "ALT",
            "alt": "ALT",
            "–∞—Å—Ç": "AST",
            "ast": "AST",
            "–±–∏–ª–∏—Ä—É–±–∏–Ω": "BILI",
            "bilirubin": "BILI",
            "–∫—Ä–µ–∞—Ç–∏–Ω–∏–Ω": "CREA",
            "creatinine": "CREA",
            "–º–æ—á–µ–≤–∏–Ω–∞": "UREA",
            "urea": "UREA",
            "–∂–µ–ª–µ–∑–æ": "FE",
            "iron": "FE",
            "fe": "FE",
            "—Ñ–µ—Ä—Ä–∏—Ç–∏–Ω": "FERR",
            "ferritin": "FERR",
            "–≤–∏—Ç–∞–º–∏–Ω b12": "B12",
            "b12": "B12",
            "–≤–∏—Ç–∞–º–∏–Ω d": "D3",
            "d3": "D3",
            "–∫–∞–ª—å—Ü–∏–π": "CA",
            "calcium": "CA",
            "–º–∞–≥–Ω–∏–π": "MG",
            "magnesium": "MG",
        }
        
        for key, code in mappings.items():
            if key in name_lower:
                return code
        
        # Return original if no mapping found
        return name.upper()[:10]
    
    def _format_biomarkers_for_prompt(self, biomarkers: List[Dict]) -> str:
        """Format biomarkers for AI prompt."""
        lines = []
        for b in biomarkers:
            status = b.get("status", "unknown")
            status_emoji = {
                "normal": "‚úÖ",
                "low": "‚¨áÔ∏è",
                "high": "‚¨ÜÔ∏è",
                "critical_low": "‚ùå‚¨áÔ∏è",
                "critical_high": "‚ùå‚¨ÜÔ∏è",
            }.get(status, "‚ùì")
            
            ref_text = ""
            if b.get("ref_min") and b.get("ref_max"):
                ref_text = f" (–Ω–æ—Ä–º–∞: {b['ref_min']}-{b['ref_max']})"
            
            lines.append(
                f"{status_emoji} {b.get('code', 'N/A')}: "
                f"{b.get('value', 'N/A')} {b.get('unit', '')}{ref_text}"
            )
        
        return "\n".join(lines)
    
    def _format_products_for_prompt(self, products: List[Dict]) -> str:
        """Format products for AI prompt."""
        lines = []
        for p in products:
            ingredients = p.get("active_ingredients", "")
            benefits = p.get("health_benefits", "")
            
            lines.append(
                f"ID:{p['id']} | {p['name']} | "
                f"–°–æ—Å—Ç–∞–≤: {ingredients} | –ü–æ–ª—å–∑–∞: {benefits}"
            )
        
        return "\n".join(lines)
    
    def _generate_simple_summary(self, biomarkers: List[Dict]) -> str:
        """Generate simple summary without AI."""
        normal = [b for b in biomarkers if b.get("status") == "normal"]
        low = [b for b in biomarkers if b.get("status") == "low"]
        high = [b for b in biomarkers if b.get("status") == "high"]
        critical = [b for b in biomarkers if b.get("status") in ("critical_low", "critical_high")]
        
        summary = "üìä **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞**\n\n"
        
        if critical:
            summary += "‚ùå **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è:**\n"
            for b in critical:
                summary += f"- {b.get('code')}: {b.get('value')} {b.get('unit')}\n"
            summary += "\n"
        
        if low:
            summary += "‚¨áÔ∏è **–ù–∏–∂–µ –Ω–æ—Ä–º—ã:**\n"
            for b in low:
                summary += f"- {b.get('code')}: {b.get('value')} {b.get('unit')}\n"
            summary += "\n"
        
        if high:
            summary += "‚¨ÜÔ∏è **–í—ã—à–µ –Ω–æ—Ä–º—ã:**\n"
            for b in high:
                summary += f"- {b.get('code')}: {b.get('value')} {b.get('unit')}\n"
            summary += "\n"
        
        summary += f"‚úÖ **–í –Ω–æ—Ä–º–µ:** {len(normal)} –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π\n\n"
        summary += "‚ö†Ô∏è –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –ø—Ä–æ–∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è —Å –≤—Ä–∞—á–æ–º –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."
        
        return summary
    
    def _fallback_recommendations(
        self,
        biomarkers: List[Dict],
        products: List[Dict],
    ) -> List[Dict]:
        """Simple rule-based recommendations without AI."""
        recommendations = []
        
        # Simple mapping of biomarker deficiencies to product keywords
        deficiency_keywords = {
            "FE": ["–∂–µ–ª–µ–∑–æ", "iron", "fe"],
            "FERR": ["—Ñ–µ—Ä—Ä–∏—Ç–∏–Ω", "–∂–µ–ª–µ–∑–æ", "iron"],
            "B12": ["b12", "–±12", "–∫–æ–±–∞–ª–∞–º–∏–Ω"],
            "D3": ["–≤–∏—Ç–∞–º–∏–Ω d", "d3", "—Ö–æ–ª–µ–∫–∞–ª—å—Ü–∏—Ñ–µ—Ä–æ–ª"],
            "MG": ["–º–∞–≥–Ω–∏–π", "magnesium"],
            "ZN": ["—Ü–∏–Ω–∫", "zinc"],
            "CA": ["–∫–∞–ª—å—Ü–∏–π", "calcium"],
        }
        
        for bio in biomarkers:
            if bio.get("status") not in ("low", "critical_low"):
                continue
            
            code = bio.get("code", "").upper()
            keywords = deficiency_keywords.get(code, [])
            
            if not keywords:
                continue
            
            for product in products:
                product_text = (
                    f"{product.get('name', '')} "
                    f"{product.get('active_ingredients', '')} "
                    f"{product.get('health_benefits', '')}"
                ).lower()
                
                if any(kw in product_text for kw in keywords):
                    recommendations.append({
                        "product_id": product["id"],
                        "biomarker_code": code,
                        "reason": f"–°–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è –≤–æ—Å–ø–æ–ª–Ω–µ–Ω–∏—è –¥–µ—Ñ–∏—Ü–∏—Ç–∞ {code}",
                        "priority": 1 if bio.get("status") == "critical_low" else 2,
                        "confidence": 0.6,
                    })
        
        return recommendations

