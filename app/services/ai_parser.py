"""
AI Parser Service for structuring medical analysis data.
Uses OpenAI GPT to extract and normalize biomarker values from OCR text.
"""

import json
import logging
import re
from typing import Dict, List, Optional, Any

from openai import AsyncOpenAI

from app.core.config import settings
from app.models.analysis import LabProvider

logger = logging.getLogger(__name__)


# System prompt for GPT
EXTRACTION_SYSTEM_PROMPT = """–¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –∏–∑–≤–ª–µ—á—å –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–æ–≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –±–∏–æ–º–∞—Ä–∫–µ—Ä–∞—Ö.

–ü—Ä–∞–≤–∏–ª–∞:
1. –ò–∑–≤–ª–µ–∫–∞–π –¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞, –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –¥–∞–Ω–Ω—ã–µ
2. –ü—Ä–∏–≤–æ–¥–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –∫–æ–¥–∞–º (HGB, RBC, WBC, FE, B12, D3, TSH –∏ —Ç.–¥.)
3. –°–æ—Ö—Ä–∞–Ω—è–π –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è –≤ –ø–æ–ª–µ raw_name
4. –ò–∑–≤–ª–µ–∫–∞–π —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
5. –û–ø—Ä–µ–¥–µ–ª—è–π –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
6. –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –∏–∑–≤–ª–µ—á—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, –ø—Ä–æ–ø—É—Å–∫–∞–π –µ–≥–æ

–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∫–æ–¥—ã –±–∏–æ–º–∞—Ä–∫–µ—Ä–æ–≤:
- HGB (–ì–µ–º–æ–≥–ª–æ–±–∏–Ω)
- RBC (–≠—Ä–∏—Ç—Ä–æ—Ü–∏—Ç—ã)
- WBC (–õ–µ–π–∫–æ—Ü–∏—Ç—ã)
- PLT (–¢—Ä–æ–º–±–æ—Ü–∏—Ç—ã)
- HCT (–ì–µ–º–∞—Ç–æ–∫—Ä–∏—Ç)
- MCV (–°—Ä–µ–¥–Ω–∏–π –æ–±—ä–µ–º —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç–∞)
- MCH (–°—Ä–µ–¥–Ω–µ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≥–µ–º–æ–≥–ª–æ–±–∏–Ω–∞)
- MCHC (–°—Ä–µ–¥–Ω—è—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è –≥–µ–º–æ–≥–ª–æ–±–∏–Ω–∞)
- ESR (–°–û–≠)
- GLU (–ì–ª—é–∫–æ–∑–∞)
- CHOL (–•–æ–ª–µ—Å—Ç–µ—Ä–∏–Ω –æ–±—â–∏–π)
- HDL (–õ–ü–í–ü)
- LDL (–õ–ü–ù–ü)
- TG (–¢—Ä–∏–≥–ª–∏—Ü–µ—Ä–∏–¥—ã)
- ALT (–ê–õ–¢)
- AST (–ê–°–¢)
- BILI (–ë–∏–ª–∏—Ä—É–±–∏–Ω –æ–±—â–∏–π)
- CREA (–ö—Ä–µ–∞—Ç–∏–Ω–∏–Ω)
- UREA (–ú–æ—á–µ–≤–∏–Ω–∞)
- TP (–û–±—â–∏–π –±–µ–ª–æ–∫)
- ALB (–ê–ª—å–±—É–º–∏–Ω)
- FE (–ñ–µ–ª–µ–∑–æ)
- FERR (–§–µ—Ä—Ä–∏—Ç–∏–Ω)
- B12 (–í–∏—Ç–∞–º–∏–Ω B12)
- FOLATE (–§–æ–ª–∏–µ–≤–∞—è –∫–∏—Å–ª–æ—Ç–∞)
- D3 (–í–∏—Ç–∞–º–∏–Ω D)
- TSH (–¢–¢–ì)
- T3 (–¢3 —Å–≤–æ–±–æ–¥–Ω—ã–π)
- T4 (–¢4 —Å–≤–æ–±–æ–¥–Ω—ã–π)
- CRP (–°-—Ä–µ–∞–∫—Ç–∏–≤–Ω—ã–π –±–µ–ª–æ–∫)
- CA (–ö–∞–ª—å—Ü–∏–π)
- MG (–ú–∞–≥–Ω–∏–π)
- K (–ö–∞–ª–∏–π)
- NA (–ù–∞—Ç—Ä–∏–π)
- ZN (–¶–∏–Ω–∫)

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –±–µ–∑ markdown-—Ä–∞–∑–º–µ—Ç–∫–∏."""

EXTRACTION_USER_PROMPT = """–ò–∑–≤–ª–µ–∫–∏ –±–∏–æ–º–∞—Ä–∫–µ—Ä—ã –∏–∑ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–æ–≤:

```
{ocr_text}
```

–í–µ—Ä–Ω–∏ JSON –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
{{
    "lab_name": "–Ω–∞–∑–≤–∞–Ω–∏–µ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –µ—Å—Ç—å",
    "analysis_date": "–¥–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD –µ—Å–ª–∏ –µ—Å—Ç—å",
    "biomarkers": [
        {{
            "code": "—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∫–æ–¥ (HGB, FE, TSH –∏ —Ç.–¥.)",
            "raw_name": "–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞",
            "value": —á–∏—Å–ª–æ–≤–æ–µ_–∑–Ω–∞—á–µ–Ω–∏–µ,
            "unit": "–µ–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è",
            "ref_min": –º–∏–Ω–∏–º—É–º_–Ω–æ—Ä–º—ã_–∏–ª–∏_null,
            "ref_max": –º–∞–∫—Å–∏–º—É–º_–Ω–æ—Ä–º—ã_–∏–ª–∏_null
        }}
    ]
}}"""


SUMMARY_SYSTEM_PROMPT = """–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π –≤—Ä–∞—á-—Ç–µ—Ä–∞–ø–µ–≤—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –¥–∞—Ç—å –∫—Ä–∞—Ç–∫—É—é, –ø–æ–Ω—è—Ç–Ω—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–æ–≤ –¥–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–∞.

–ü—Ä–∞–≤–∏–ª–∞:
1. –ü–∏—à–∏ –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º, –∏–∑–±–µ–≥–∞–π —Å–ª–æ–∂–Ω—ã—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
2. –°–Ω–∞—á–∞–ª–∞ —É–∫–∞–∂–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –≤–Ω–µ –Ω–æ—Ä–º—ã
3. –û–±—ä—è—Å–Ω–∏, —á—Ç–æ –º–æ–≥—É—Ç –æ–∑–Ω–∞—á–∞—Ç—å –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
4. –î–∞–π –æ–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–Ω–æ –Ω–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç—ã)
5. –ù–∞–ø–æ–º–Ω–∏, —á—Ç–æ –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é –¥–æ–ª–∂–µ–Ω –¥–∞–≤–∞—Ç—å –≤—Ä–∞—á

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
- –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ (‚úÖ –Ω–æ—Ä–º–∞, ‚ö†Ô∏è –≤–Ω–∏–º–∞–Ω–∏–µ, ‚ùå –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ)
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º
- –ë—É–¥—å –ª–∞–∫–æ–Ω–∏—á–µ–Ω"""


class AIParserService:
    """
    Service for AI-powered analysis of medical documents.
    Extracts structured biomarker data and generates interpretations.
    """
    
    def __init__(self):
        """Initialize the AI parser service."""
        self.client = AsyncOpenAI(
            api_key=settings.openai_api_key,
            base_url=settings.openai_base_url,
        )
        self.model = settings.openai_model
    
    async def extract_biomarkers(
        self,
        ocr_text: str,
        lab_provider: Optional[LabProvider] = None,
    ) -> Dict[str, Any]:
        """
        Extract biomarkers from OCR text using GPT.
        
        Args:
            ocr_text: Raw text from OCR
            lab_provider: Known lab provider for better parsing
            
        Returns:
            Dictionary with extracted data:
            {
                "lab_name": str,
                "analysis_date": str,
                "biomarkers": List[Dict]
            }
        """
        if not settings.openai_api_key:
            logger.warning("OpenAI API key not configured, using fallback parser")
            return self._fallback_parse(ocr_text)
        
        try:
            # Add lab context if known
            context = ""
            if lab_provider:
                context = f"\n\n–ò–∑–≤–µ—Å—Ç–Ω–æ, —á—Ç–æ —ç—Ç–æ –∞–Ω–∞–ª–∏–∑ –∏–∑ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏: {lab_provider.value}"
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": EXTRACTION_SYSTEM_PROMPT},
                    {
                        "role": "user",
                        "content": EXTRACTION_USER_PROMPT.format(
                            ocr_text=ocr_text[:8000]  # Limit text length
                        ) + context
                    },
                ],
                temperature=0.1,  # Low temperature for consistent extraction
                max_tokens=4000,
                response_format={"type": "json_object"},
            )
            
            result_text = response.choices[0].message.content
            result = json.loads(result_text)
            
            # Validate and clean results
            result = self._validate_extraction(result)
            
            logger.info(
                f"AI extraction completed: {len(result.get('biomarkers', []))} biomarkers found"
            )
            
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse AI response as JSON: {e}")
            return self._fallback_parse(ocr_text)
        except Exception as e:
            logger.error(f"AI extraction failed: {e}")
            return self._fallback_parse(ocr_text)
    
    async def generate_summary(
        self,
        biomarkers: List[Dict[str, Any]],
        user_gender: Optional[str] = None,
        user_age: Optional[int] = None,
    ) -> str:
        """
        Generate a human-readable summary of analysis results.
        
        Args:
            biomarkers: List of biomarker data with status
            user_gender: User's gender for context
            user_age: User's age for context
            
        Returns:
            Human-readable summary text
        """
        if not settings.openai_api_key:
            return self._generate_simple_summary(biomarkers)
        
        try:
            # Prepare biomarker data for prompt
            biomarker_text = self._format_biomarkers_for_prompt(biomarkers)
            
            context = ""
            if user_gender or user_age:
                context = f"\n\n–ü–∞—Ü–∏–µ–Ω—Ç: "
                if user_gender:
                    context += f"{'–º—É–∂—á–∏–Ω–∞' if user_gender == 'male' else '–∂–µ–Ω—â–∏–Ω–∞'}"
                if user_age:
                    context += f", {user_age} –ª–µ—Ç"
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": SUMMARY_SYSTEM_PROMPT},
                    {
                        "role": "user",
                        "content": f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–æ–≤:{context}\n\n{biomarker_text}"
                    },
                ],
                temperature=0.7,
                max_tokens=1500,
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Summary generation failed: {e}")
            return self._generate_simple_summary(biomarkers)
    
    async def generate_recommendations(
        self,
        biomarkers: List[Dict[str, Any]],
        available_products: List[Dict[str, Any]],
    ) -> List[Dict[str, Any]]:
        """
        Generate product recommendations based on biomarker deficiencies.
        
        Args:
            biomarkers: List of biomarkers with status
            available_products: List of products from catalog
            
        Returns:
            List of recommendations with reasons
        """
        if not settings.openai_api_key or not available_products:
            return self._fallback_recommendations(biomarkers, available_products)
        
        try:
            # Filter biomarkers that need attention
            problem_biomarkers = [
                b for b in biomarkers
                if b.get("status") in ("low", "high", "critical_low", "critical_high")
            ]
            
            if not problem_biomarkers:
                return []
            
            # Prepare data for prompt
            biomarker_text = self._format_biomarkers_for_prompt(problem_biomarkers)
            products_text = self._format_products_for_prompt(available_products[:50])
            
            prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π –≤ –∞–Ω–∞–ª–∏–∑–∞—Ö –ø–æ–¥–±–µ—Ä–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–æ–±–∞–≤–∫–∏ –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞.

–û—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –≤ –∞–Ω–∞–ª–∏–∑–∞—Ö:
{biomarker_text}

–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã:
{products_text}

–í–µ—Ä–Ω–∏ JSON:
{{
    "recommendations": [
        {{
            "product_id": id_—Ç–æ–≤–∞—Ä–∞,
            "biomarker_code": "–∫–æ–¥_–±–∏–æ–º–∞—Ä–∫–µ—Ä–∞",
            "reason": "–ø–æ—á–µ–º—É —ç—Ç–æ—Ç —Ç–æ–≤–∞—Ä –ø–æ–º–æ–∂–µ—Ç",
            "priority": 1-5,
            "confidence": 0.0-1.0
        }}
    ]
}}"""
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "–¢—ã ‚Äî –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –ø–æ–¥–±–æ—Ä—É –ë–ê–î–æ–≤. –†–µ–∫–æ–º–µ–Ω–¥—É–π —Ç–æ–ª—å–∫–æ —Ç–µ —Ç–æ–≤–∞—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–ª—å–Ω–æ –º–æ–≥—É—Ç –ø–æ–º–æ—á—å —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –¥–µ—Ñ–∏—Ü–∏—Ç–∞–º–∏. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON."
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.3,
                max_tokens=2000,
                response_format={"type": "json_object"},
            )
            
            result = json.loads(response.choices[0].message.content)
            return result.get("recommendations", [])
            
        except Exception as e:
            logger.error(f"Recommendation generation failed: {e}")
            return self._fallback_recommendations(biomarkers, available_products)
    
    def _validate_extraction(self, result: Dict) -> Dict:
        """Validate and clean extracted data."""
        validated = {
            "lab_name": result.get("lab_name"),
            "analysis_date": result.get("analysis_date"),
            "biomarkers": [],
        }
        
        for bio in result.get("biomarkers", []):
            # Skip invalid entries
            if not bio.get("code") or bio.get("value") is None:
                continue
            
            try:
                value = float(bio["value"])
            except (ValueError, TypeError):
                continue
            
            validated["biomarkers"].append({
                "code": bio["code"].upper(),
                "raw_name": bio.get("raw_name", ""),
                "value": value,
                "unit": bio.get("unit", ""),
                "ref_min": self._safe_float(bio.get("ref_min")),
                "ref_max": self._safe_float(bio.get("ref_max")),
            })
        
        return validated
    
    def _safe_float(self, value: Any) -> Optional[float]:
        """Safely convert value to float."""
        if value is None:
            return None
        try:
            return float(value)
        except (ValueError, TypeError):
            return None
    
    def _fallback_parse(self, ocr_text: str) -> Dict:
        """
        Fallback regex-based parser when AI is unavailable.
        Handles common formats from Russian labs.
        """
        biomarkers = []
        
        # Common patterns for lab results
        patterns = [
            # "–ì–µ–º–æ–≥–ª–æ–±–∏–Ω: 140 –≥/–ª (120-160)"
            r"([–ê-–Ø–∞-—èA-Za-z\s]+):\s*([\d.,]+)\s*([–∞-—è–ê-–Øa-zA-Z/¬≥¬≤]+)?\s*(?:\(?([\d.,]+)\s*[-‚Äì]\s*([\d.,]+)\)?)?",
            # "HGB 140 g/L"
            r"([A-Z]{2,5})\s+([\d.,]+)\s*([–∞-—è–ê-–Øa-zA-Z/¬≥¬≤]+)?",
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, ocr_text)
            for match in matches:
                if len(match) >= 2:
                    name = match[0].strip()
                    try:
                        value = float(match[1].replace(",", "."))
                    except ValueError:
                        continue
                    
                    unit = match[2] if len(match) > 2 else ""
                    ref_min = self._safe_float(match[3]) if len(match) > 3 else None
                    ref_max = self._safe_float(match[4]) if len(match) > 4 else None
                    
                    # Try to normalize code
                    code = self._normalize_biomarker_code(name)
                    
                    biomarkers.append({
                        "code": code,
                        "raw_name": name,
                        "value": value,
                        "unit": unit,
                        "ref_min": ref_min,
                        "ref_max": ref_max,
                    })
        
        return {
            "lab_name": None,
            "analysis_date": None,
            "biomarkers": biomarkers,
        }
    
    def _normalize_biomarker_code(self, name: str) -> str:
        """Normalize biomarker name to standard code."""
        name_lower = name.lower().strip()
        
        mappings = {
            "–≥–µ–º–æ–≥–ª–æ–±–∏–Ω": "HGB",
            "hemoglobin": "HGB",
            "hgb": "HGB",
            "hb": "HGB",
            "—ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç—ã": "RBC",
            "rbc": "RBC",
            "–ª–µ–π–∫–æ—Ü–∏—Ç—ã": "WBC",
            "wbc": "WBC",
            "—Ç—Ä–æ–º–±–æ—Ü–∏—Ç—ã": "PLT",
            "plt": "PLT",
            "–≥–µ–º–∞—Ç–æ–∫—Ä–∏—Ç": "HCT",
            "hct": "HCT",
            "—Å–æ—ç": "ESR",
            "esr": "ESR",
            "–≥–ª—é–∫–æ–∑–∞": "GLU",
            "glucose": "GLU",
            "—Ö–æ–ª–µ—Å—Ç–µ—Ä–∏–Ω": "CHOL",
            "cholesterol": "CHOL",
            "–∞–ª—Ç": "ALT",
            "alt": "ALT",
            "–∞—Å—Ç": "AST",
            "ast": "AST",
            "–±–∏–ª–∏—Ä—É–±–∏–Ω": "BILI",
            "bilirubin": "BILI",
            "–∫—Ä–µ–∞—Ç–∏–Ω–∏–Ω": "CREA",
            "creatinine": "CREA",
            "–º–æ—á–µ–≤–∏–Ω–∞": "UREA",
            "urea": "UREA",
            "–∂–µ–ª–µ–∑–æ": "FE",
            "iron": "FE",
            "fe": "FE",
            "—Ñ–µ—Ä—Ä–∏—Ç–∏–Ω": "FERR",
            "ferritin": "FERR",
            "–≤–∏—Ç–∞–º–∏–Ω b12": "B12",
            "b12": "B12",
            "–≤–∏—Ç–∞–º–∏–Ω d": "D3",
            "d3": "D3",
            "—Ç—Ç–≥": "TSH",
            "tsh": "TSH",
            "–∫–∞–ª—å—Ü–∏–π": "CA",
            "calcium": "CA",
            "–º–∞–≥–Ω–∏–π": "MG",
            "magnesium": "MG",
        }
        
        for key, code in mappings.items():
            if key in name_lower:
                return code
        
        # Return original if no mapping found
        return name.upper()[:10]
    
    def _format_biomarkers_for_prompt(self, biomarkers: List[Dict]) -> str:
        """Format biomarkers for AI prompt."""
        lines = []
        for b in biomarkers:
            status = b.get("status", "unknown")
            status_emoji = {
                "normal": "‚úÖ",
                "low": "‚¨áÔ∏è",
                "high": "‚¨ÜÔ∏è",
                "critical_low": "‚ùå‚¨áÔ∏è",
                "critical_high": "‚ùå‚¨ÜÔ∏è",
            }.get(status, "‚ùì")
            
            ref_text = ""
            if b.get("ref_min") and b.get("ref_max"):
                ref_text = f" (–Ω–æ—Ä–º–∞: {b['ref_min']}-{b['ref_max']})"
            
            lines.append(
                f"{status_emoji} {b.get('code', 'N/A')}: "
                f"{b.get('value', 'N/A')} {b.get('unit', '')}{ref_text}"
            )
        
        return "\n".join(lines)
    
    def _format_products_for_prompt(self, products: List[Dict]) -> str:
        """Format products for AI prompt."""
        lines = []
        for p in products:
            ingredients = p.get("active_ingredients", "")
            benefits = p.get("health_benefits", "")
            
            lines.append(
                f"ID:{p['id']} | {p['name']} | "
                f"–°–æ—Å—Ç–∞–≤: {ingredients} | –ü–æ–ª—å–∑–∞: {benefits}"
            )
        
        return "\n".join(lines)
    
    def _generate_simple_summary(self, biomarkers: List[Dict]) -> str:
        """Generate simple summary without AI."""
        normal = [b for b in biomarkers if b.get("status") == "normal"]
        low = [b for b in biomarkers if b.get("status") == "low"]
        high = [b for b in biomarkers if b.get("status") == "high"]
        critical = [b for b in biomarkers if b.get("status") in ("critical_low", "critical_high")]
        
        summary = "üìä **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞**\n\n"
        
        if critical:
            summary += "‚ùå **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è:**\n"
            for b in critical:
                summary += f"- {b.get('code')}: {b.get('value')} {b.get('unit')}\n"
            summary += "\n"
        
        if low:
            summary += "‚¨áÔ∏è **–ù–∏–∂–µ –Ω–æ—Ä–º—ã:**\n"
            for b in low:
                summary += f"- {b.get('code')}: {b.get('value')} {b.get('unit')}\n"
            summary += "\n"
        
        if high:
            summary += "‚¨ÜÔ∏è **–í—ã—à–µ –Ω–æ—Ä–º—ã:**\n"
            for b in high:
                summary += f"- {b.get('code')}: {b.get('value')} {b.get('unit')}\n"
            summary += "\n"
        
        summary += f"‚úÖ **–í –Ω–æ—Ä–º–µ:** {len(normal)} –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π\n\n"
        summary += "‚ö†Ô∏è –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –ø—Ä–æ–∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è —Å –≤—Ä–∞—á–æ–º –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."
        
        return summary
    
    def _fallback_recommendations(
        self,
        biomarkers: List[Dict],
        products: List[Dict],
    ) -> List[Dict]:
        """Simple rule-based recommendations without AI."""
        recommendations = []
        
        # Simple mapping of biomarker deficiencies to product keywords
        deficiency_keywords = {
            "FE": ["–∂–µ–ª–µ–∑–æ", "iron", "fe"],
            "FERR": ["—Ñ–µ—Ä—Ä–∏—Ç–∏–Ω", "–∂–µ–ª–µ–∑–æ", "iron"],
            "B12": ["b12", "–±12", "–∫–æ–±–∞–ª–∞–º–∏–Ω"],
            "D3": ["–≤–∏—Ç–∞–º–∏–Ω d", "d3", "—Ö–æ–ª–µ–∫–∞–ª—å—Ü–∏—Ñ–µ—Ä–æ–ª"],
            "MG": ["–º–∞–≥–Ω–∏–π", "magnesium"],
            "ZN": ["—Ü–∏–Ω–∫", "zinc"],
            "CA": ["–∫–∞–ª—å—Ü–∏–π", "calcium"],
        }
        
        for bio in biomarkers:
            if bio.get("status") not in ("low", "critical_low"):
                continue
            
            code = bio.get("code", "").upper()
            keywords = deficiency_keywords.get(code, [])
            
            if not keywords:
                continue
            
            for product in products:
                product_text = (
                    f"{product.get('name', '')} "
                    f"{product.get('active_ingredients', '')} "
                    f"{product.get('health_benefits', '')}"
                ).lower()
                
                if any(kw in product_text for kw in keywords):
                    recommendations.append({
                        "product_id": product["id"],
                        "biomarker_code": code,
                        "reason": f"–°–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è –≤–æ—Å–ø–æ–ª–Ω–µ–Ω–∏—è –¥–µ—Ñ–∏—Ü–∏—Ç–∞ {code}",
                        "priority": 1 if bio.get("status") == "critical_low" else 2,
                        "confidence": 0.6,
                    })
        
        return recommendations

