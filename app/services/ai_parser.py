"""
AI Parser Service for structuring medical analysis data.
Uses OpenAI GPT to extract and normalize biomarker values from OCR text.
"""

import json
import logging
import re
from typing import Dict, List, Optional, Any

from openai import AsyncOpenAI

from app.core.config import settings
from app.models.analysis import LabProvider

logger = logging.getLogger(__name__)


# System prompt for GPT
EXTRACTION_SYSTEM_PROMPT = """–¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –∏–∑–≤–ª–µ—á—å –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–æ–≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –±–∏–æ–º–∞—Ä–∫–µ—Ä–∞—Ö.

–ü—Ä–∞–≤–∏–ª–∞:
1. –ò–∑–≤–ª–µ–∫–∞–π –¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞, –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –¥–∞–Ω–Ω—ã–µ
2. –ü—Ä–∏–≤–æ–¥–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –∫–æ–¥–∞–º (HGB, RBC, WBC, FE, B12, D3, TSH –∏ —Ç.–¥.)
3. –°–æ—Ö—Ä–∞–Ω—è–π –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è –≤ –ø–æ–ª–µ raw_name
4. –ò–∑–≤–ª–µ–∫–∞–π —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
5. –û–ø—Ä–µ–¥–µ–ª—è–π –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
6. –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –∏–∑–≤–ª–µ—á—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, –ø—Ä–æ–ø—É—Å–∫–∞–π –µ–≥–æ

–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∫–æ–¥—ã –±–∏–æ–º–∞—Ä–∫–µ—Ä–æ–≤:

–ì–ï–ú–ê–¢–û–õ–û–ì–ò–Ø:
- HGB (–ì–µ–º–æ–≥–ª–æ–±–∏–Ω)
- RBC (–≠—Ä–∏—Ç—Ä–æ—Ü–∏—Ç—ã)
- WBC (–õ–µ–π–∫–æ—Ü–∏—Ç—ã)
- PLT (–¢—Ä–æ–º–±–æ—Ü–∏—Ç—ã)
- HCT (–ì–µ–º–∞—Ç–æ–∫—Ä–∏—Ç)
- MCV (–°—Ä–µ–¥–Ω–∏–π –æ–±—ä–µ–º —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç–∞)
- MCH (–°—Ä–µ–¥–Ω–µ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≥–µ–º–æ–≥–ª–æ–±–∏–Ω–∞)
- MCHC (–°—Ä–µ–¥–Ω—è—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è –≥–µ–º–æ–≥–ª–æ–±–∏–Ω–∞)
- RDW (–®–∏—Ä–∏–Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç–æ–≤)
- MPV (–°—Ä–µ–¥–Ω–∏–π –æ–±—ä–µ–º —Ç—Ä–æ–º–±–æ—Ü–∏—Ç–æ–≤)
- PCT (–¢—Ä–æ–º–±–æ–∫—Ä–∏—Ç)
- ESR (–°–û–≠)
- NEUT (–ù–µ–π—Ç—Ä–æ—Ñ–∏–ª—ã)
- LYMPH (–õ–∏–º—Ñ–æ—Ü–∏—Ç—ã)
- MONO (–ú–æ–Ω–æ—Ü–∏—Ç—ã)
- EOS (–≠–æ–∑–∏–Ω–æ—Ñ–∏–ª—ã)
- BASO (–ë–∞–∑–æ—Ñ–∏–ª—ã)

–ë–ò–û–•–ò–ú–ò–Ø:
- GLU (–ì–ª—é–∫–æ–∑–∞)
- TP (–û–±—â–∏–π –±–µ–ª–æ–∫)
- ALB (–ê–ª—å–±—É–º–∏–Ω)
- LDH (–õ–î–ì, –ª–∞–∫—Ç–∞—Ç–¥–µ–≥–∏–¥—Ä–æ–≥–µ–Ω–∞–∑–∞)
- CK (–ö–§–ö, –∫—Ä–µ–∞—Ç–∏–Ω–∫–∏–Ω–∞–∑–∞)
- AMY (–ê–º–∏–ª–∞–∑–∞)
- LIPA (–õ–∏–ø–∞–∑–∞)

–ü–ï–ß–ï–ù–¨:
- ALT (–ê–õ–¢)
- AST (–ê–°–¢)
- GGT (–ì–ì–¢–ü, –≥–∞–º–º–∞-–≥–ª—É—Ç–∞–º–∏–ª—Ç—Ä–∞–Ω—Å—Ñ–µ—Ä–∞–∑–∞)
- ALP (–©–µ–ª–æ—á–Ω–∞—è —Ñ–æ—Å—Ñ–∞—Ç–∞–∑–∞)
- BILI (–ë–∏–ª–∏—Ä—É–±–∏–Ω –æ–±—â–∏–π)
- DBILI (–ë–∏–ª–∏—Ä—É–±–∏–Ω –ø—Ä—è–º–æ–π)

–ü–û–ß–ö–ò:
- CREA (–ö—Ä–µ–∞—Ç–∏–Ω–∏–Ω)
- UREA (–ú–æ—á–µ–≤–∏–Ω–∞)
- UA (–ú–æ—á–µ–≤–∞—è –∫–∏—Å–ª–æ—Ç–∞)
- GFR (–°–ö–§)

–õ–ò–ü–ò–î–´:
- CHOL (–•–æ–ª–µ—Å—Ç–µ—Ä–∏–Ω –æ–±—â–∏–π)
- HDL (–õ–ü–í–ü)
- LDL (–õ–ü–ù–ü)
- TG (–¢—Ä–∏–≥–ª–∏—Ü–µ—Ä–∏–¥—ã)

–ú–ò–ù–ï–†–ê–õ–´:
- FE (–ñ–µ–ª–µ–∑–æ)
- FERR (–§–µ—Ä—Ä–∏—Ç–∏–Ω)
- CA (–ö–∞–ª—å—Ü–∏–π)
- MG (–ú–∞–≥–Ω–∏–π)
- K (–ö–∞–ª–∏–π)
- NA (–ù–∞—Ç—Ä–∏–π)
- P (–§–æ—Å—Ñ–æ—Ä)
- ZN (–¶–∏–Ω–∫)

–í–ò–¢–ê–ú–ò–ù–´:
- B12 (–í–∏—Ç–∞–º–∏–Ω B12)
- FOLATE (–§–æ–ª–∏–µ–≤–∞—è –∫–∏—Å–ª–æ—Ç–∞)
- D3 (–í–∏—Ç–∞–º–∏–Ω D)

–ì–û–†–ú–û–ù–´ / –©–ò–¢–û–í–ò–î–ö–ê:
- TSH (–¢–¢–ì)
- T3 (–¢3 —Å–≤–æ–±–æ–¥–Ω—ã–π)
- T4 (–¢4 —Å–≤–æ–±–æ–¥–Ω—ã–π)
- FT3 (–¢3 —Å–≤–æ–±–æ–¥–Ω—ã–π)
- FT4 (–¢4 —Å–≤–æ–±–æ–¥–Ω—ã–π)

–ü–û–õ–û–í–´–ï –ì–û–†–ú–û–ù–´ –ò –î–†.:
- TEST (–¢–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω –æ–±—â–∏–π/—Å–≤–æ–±–æ–¥–Ω—ã–π)
- SHBG (–ì–°–ü–ì, —Å–µ–∫—Å-—Å–≤—è–∑—ã–≤–∞—é—â–∏–π –≥–ª–æ–±—É–ª–∏–Ω)
- PROL (–ü—Ä–æ–ª–∞–∫—Ç–∏–Ω)
- FAI (–ò–Ω–¥–µ–∫—Å —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ —Ç–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω–∞, –ò–°–¢)
- E2 (–≠—Å—Ç—Ä–∞–¥–∏–æ–ª)
- PROG (–ü—Ä–æ–≥–µ—Å—Ç–µ—Ä–æ–Ω)
- LH (–õ–ì)
- FSH (–§–°–ì)
- CORT (–ö–æ—Ä—Ç–∏–∑–æ–ª)
- INS (–ò–Ω—Å—É–ª–∏–Ω)

–í–û–°–ü–ê–õ–ï–ù–ò–ï:
- CRP (–°-—Ä–µ–∞–∫—Ç–∏–≤–Ω—ã–π –±–µ–ª–æ–∫)

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –±–µ–∑ markdown-—Ä–∞–∑–º–µ—Ç–∫–∏."""

EXTRACTION_USER_PROMPT = """–ò–∑–≤–ª–µ–∫–∏ –±–∏–æ–º–∞—Ä–∫–µ—Ä—ã –∏–∑ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–æ–≤:

```
{ocr_text}
```

–í–µ—Ä–Ω–∏ JSON –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
{{
    "lab_name": "–Ω–∞–∑–≤–∞–Ω–∏–µ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –µ—Å—Ç—å",
    "analysis_date": "–¥–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD –µ—Å–ª–∏ –µ—Å—Ç—å",
    "biomarkers": [
        {{
            "code": "—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∫–æ–¥ (HGB, FE, TSH –∏ —Ç.–¥.)",
            "raw_name": "–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞",
            "value": —á–∏—Å–ª–æ–≤–æ–µ_–∑–Ω–∞—á–µ–Ω–∏–µ,
            "unit": "–µ–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è",
            "ref_min": –º–∏–Ω–∏–º—É–º_–Ω–æ—Ä–º—ã_–∏–ª–∏_null,
            "ref_max": –º–∞–∫—Å–∏–º—É–º_–Ω–æ—Ä–º—ã_–∏–ª–∏_null
        }}
    ]
}}"""


SUMMARY_SYSTEM_PROMPT = """–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π –≤—Ä–∞—á-—Ç–µ—Ä–∞–ø–µ–≤—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –¥–∞—Ç—å –ü–ï–†–°–û–ù–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–£–Æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–æ–≤ —Å —É—á—ë—Ç–æ–º –ø—Ä–æ—Ñ–∏–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–∞.

–ü—Ä–∞–≤–∏–ª–∞:
1. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —É—á–∏—Ç—ã–≤–∞–π –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–∞ (—Ä–æ—Å—Ç, –≤–µ—Å, –≤–æ–∑—Ä–∞—Å—Ç, –ø–æ–ª, –∞–ª–ª–µ—Ä–≥–∏–∏, —Ö—Ä–æ–Ω–∏—á–µ—Å–∫–∏–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è)
2. –ü–∏—à–∏ –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º, –∏–∑–±–µ–≥–∞–π —Å–ª–æ–∂–Ω—ã—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
3. –°–Ω–∞—á–∞–ª–∞ —É–∫–∞–∂–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –≤–Ω–µ –Ω–æ—Ä–º—ã
4. –û–±—ä—è—Å–Ω–∏, —á—Ç–æ –º–æ–≥—É—Ç –æ–∑–Ω–∞—á–∞—Ç—å –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –ò–ú–ï–ù–ù–û –î–õ–Ø –≠–¢–û–ì–û –ü–ê–¶–ò–ï–ù–¢–ê
5. –£—á–∏—Ç—ã–≤–∞–π –≤–∑–∞–∏–º–æ—Å–≤—è–∑—å –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π —Å —Ö—Ä–æ–Ω–∏—á–µ—Å–∫–∏–º–∏ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è–º–∏ –ø–∞—Ü–∏–µ–Ω—Ç–∞
6. –ï—Å–ª–∏ –µ—Å—Ç—å –∞–ª–ª–µ—Ä–≥–∏–∏ ‚Äî —É—á–∏—Ç—ã–≤–∞–π –∏—Ö –ø—Ä–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö
7. –î–∞–π –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–±—Ä–∞–∑—É –∂–∏–∑–Ω–∏
8. –ù–∞–ø–æ–º–Ω–∏, —á—Ç–æ –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é –¥–æ–ª–∂–µ–Ω –¥–∞–≤–∞—Ç—å –≤—Ä–∞—á

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
- –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ (‚úÖ –Ω–æ—Ä–º–∞, ‚ö†Ô∏è –≤–Ω–∏–º–∞–Ω–∏–µ, ‚ùå –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ)
- –ù–∞—á–Ω–∏ —Å –∫—Ä–∞—Ç–∫–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–∞
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º
- –ë—É–¥—å –ª–∞–∫–æ–Ω–∏—á–µ–Ω –Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–µ–Ω"""


class AIParserService:
    """
    Service for AI-powered analysis of medical documents.
    Extracts structured biomarker data and generates interpretations.
    """
    
    def __init__(self):
        """Initialize the AI parser service."""
        # OpenRouter requires extra headers
        self.client = AsyncOpenAI(
            api_key=settings.openai_api_key,
            base_url=settings.openai_base_url,
            default_headers={
                "HTTP-Referer": "https://healthtracker.app",
                "X-Title": "Health Tracker Medical Analysis",
            }
        )
        self.model = settings.openai_model
        # Vision model - same as main model (gpt-4o-mini supports vision)
        self.vision_model = settings.openai_model
    
    async def extract_biomarkers_from_image(
        self,
        image_base64: str,
        content_type: str = "image/jpeg",
    ) -> Dict[str, Any]:
        """
        Extract biomarkers directly from image using GPT-4 Vision.
        Better for handwritten or low-quality scans.
        
        Args:
            image_base64: Base64 encoded image
            content_type: MIME type of the image
            
        Returns:
            Dictionary with extracted biomarkers
        """
        if not settings.openai_api_key:
            logger.warning("OpenAI API key not configured")
            return {"lab_name": None, "analysis_date": None, "biomarkers": []}
        
        try:
            logger.info("Using Vision API to extract biomarkers from image")
            
            response = await self.client.chat.completions.create(
                model=self.vision_model,
                messages=[
                    {"role": "system", "content": EXTRACTION_SYSTEM_PROMPT},
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": """–ò–∑–≤–ª–µ–∫–∏ –í–°–ï –±–∏–æ–º–∞—Ä–∫–µ—Ä—ã –∏–∑ —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ –∫—Ä–æ–≤–∏.
                                
–í–ê–ñ–ù–û: –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–π –í–°–ï –∑–Ω–∞—á–µ–Ω–∏—è, –≤–∫–ª—é—á–∞—è —Ä—É–∫–æ–ø–∏—Å–Ω—ã–µ!

–í–µ—Ä–Ω–∏ JSON:
{
    "lab_name": "–Ω–∞–∑–≤–∞–Ω–∏–µ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –µ—Å—Ç—å",
    "analysis_date": "–¥–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD –µ—Å–ª–∏ –µ—Å—Ç—å",
    "biomarkers": [
        {"code": "HGB", "raw_name": "–ì–µ–º–æ–≥–ª–æ–±–∏–Ω", "value": 132, "unit": "–≥/–ª", "ref_min": 80, "ref_max": 150}
    ]
}"""
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:{content_type};base64,{image_base64}",
                                    "detail": "high"
                                }
                            }
                        ]
                    },
                ],
                temperature=0.1,
                max_tokens=4000,
                response_format={"type": "json_object"},
            )
            
            result_text = response.choices[0].message.content
            
            # Try to extract JSON from response
            import re
            json_match = re.search(r'\{[\s\S]*\}', result_text)
            if json_match:
                result = json.loads(json_match.group())
            else:
                result = json.loads(result_text)
            
            result = self._validate_extraction(result)
            
            logger.info(f"Vision extraction completed: {len(result.get('biomarkers', []))} biomarkers found")
            
            return result
            
        except Exception as e:
            logger.error(f"Vision extraction failed: {e}")
            return {"lab_name": None, "analysis_date": None, "biomarkers": []}
    
    async def extract_biomarkers(
        self,
        ocr_text: str,
        lab_provider: Optional[LabProvider] = None,
    ) -> Dict[str, Any]:
        """
        Extract biomarkers from OCR text using GPT.
        
        Args:
            ocr_text: Raw text from OCR
            lab_provider: Known lab provider for better parsing
            
        Returns:
            Dictionary with extracted data:
            {
                "lab_name": str,
                "analysis_date": str,
                "biomarkers": List[Dict]
            }
        """
        if not settings.openai_api_key:
            logger.warning("OpenAI API key not configured, using fallback parser")
            return self._fallback_parse(ocr_text)
        
        try:
            # Add lab context if known
            context = ""
            if lab_provider:
                context = f"\n\n–ò–∑–≤–µ—Å—Ç–Ω–æ, —á—Ç–æ —ç—Ç–æ –∞–Ω–∞–ª–∏–∑ –∏–∑ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏: {lab_provider.value}"
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": EXTRACTION_SYSTEM_PROMPT},
                    {
                        "role": "user",
                        "content": EXTRACTION_USER_PROMPT.format(
                            ocr_text=ocr_text[:8000]  # Limit text length
                        ) + context
                    },
                ],
                temperature=0.1,  # Low temperature for consistent extraction
                max_tokens=4000,
                response_format={"type": "json_object"},
            )
            
            result_text = response.choices[0].message.content
            result = json.loads(result_text)
            
            # Validate and clean results
            result = self._validate_extraction(result)
            
            # Safety net: try to find missing critical biomarkers via regex
            result = self._enrich_with_regex(result, ocr_text)
            
            logger.info(
                f"AI extraction completed: {len(result.get('biomarkers', []))} biomarkers found"
            )
            
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse AI response as JSON: {e}")
            return self._fallback_parse(ocr_text)
        except Exception as e:
            logger.error(f"AI extraction failed: {e}")
            return self._fallback_parse(ocr_text)
    
    async def generate_summary(
        self,
        biomarkers: List[Dict[str, Any]],
        user_gender: Optional[str] = None,
        user_age: Optional[int] = None,
        patient_profile: Optional[Dict[str, Any]] = None,
    ) -> str:
        """
        Generate a human-readable summary of analysis results.
        
        Args:
            biomarkers: List of biomarker data with status
            user_gender: User's gender for context
            user_age: User's age for context
            patient_profile: Full patient profile data
            
        Returns:
            Human-readable summary text
        """
        if not settings.openai_api_key:
            return self._generate_simple_summary(biomarkers)
        
        try:
            # Prepare biomarker data for prompt
            biomarker_text = self._format_biomarkers_for_prompt(biomarkers)
            
            # Build comprehensive patient context
            context = "\n\nüë§ **–ü–†–û–§–ò–õ–¨ –ü–ê–¶–ò–ï–ù–¢–ê:**"
            
            if user_gender:
                context += f"\n- –ü–æ–ª: {'–º—É–∂—á–∏–Ω–∞' if user_gender == 'male' else '–∂–µ–Ω—â–∏–Ω–∞'}"
            if user_age:
                context += f"\n- –í–æ–∑—Ä–∞—Å—Ç: {user_age} –ª–µ—Ç"
            
            if patient_profile:
                # Body parameters (height, weight, waist)
                body = patient_profile.get("body_parameters", {})
                if body:
                    if body.get("height"):
                        context += f"\n- –†–æ—Å—Ç: {body['height']} —Å–º"
                    if body.get("weight"):
                        context += f"\n- –í–µ—Å: {body['weight']} –∫–≥"
                    if body.get("waist"):
                        context += f"\n- –û–±—Ö–≤–∞—Ç —Ç–∞–ª–∏–∏: {body['waist']} —Å–º"
                    # Calculate BMI if possible
                    if body.get("height") and body.get("weight"):
                        height_m = float(body["height"]) / 100
                        bmi = float(body["weight"]) / (height_m * height_m)
                        context += f"\n- –ò–ú–¢: {bmi:.1f}"
                
                # Allergies
                allergies = patient_profile.get("allergies", [])
                if allergies:
                    context += f"\n- ‚ö†Ô∏è –ê–ª–ª–µ—Ä–≥–∏–∏: {', '.join(allergies)}"
                
                # Chronic diseases
                chronic = patient_profile.get("chronic_diseases", [])
                if chronic:
                    context += f"\n- üè• –•—Ä–æ–Ω–∏—á–µ—Å–∫–∏–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è: {', '.join(chronic)}"
                
                # Hereditary diseases
                hereditary = patient_profile.get("hereditary_diseases", [])
                if hereditary:
                    context += f"\n- üß¨ –ù–∞—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è: {', '.join(hereditary)}"
                
                # Lifestyle
                lifestyle = patient_profile.get("lifestyle", {})
                if lifestyle:
                    context += f"\n- –û–±—Ä–∞–∑ –∂–∏–∑–Ω–∏: {json.dumps(lifestyle, ensure_ascii=False)}"
            
            prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–æ–≤ —Å —É—á—ë—Ç–æ–º –ø—Ä–æ—Ñ–∏–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–∞.
{context}

üìä **–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–û–í:**
{biomarker_text}

–î–∞–π –ü–ï–†–°–û–ù–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–£–Æ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É, —É—á–∏—Ç—ã–≤–∞—è –≤—Å–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –ø–∞—Ü–∏–µ–Ω—Ç–∞."""
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": SUMMARY_SYSTEM_PROMPT},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.7,
                max_tokens=2000,
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Summary generation failed: {e}")
            return self._generate_simple_summary(biomarkers)
    
    async def generate_search_keywords(
        self,
        biomarkers: List[Dict[str, Any]],
        patient_profile: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, List[str]]:
        """
        Generate search keywords for finding products based on analysis.
        
        Returns:
            Dict where key is biomarker code (or 'general') and value is list of keywords.
        """
        if not settings.openai_api_key:
            return {}
        
        try:
            # Filter problem biomarkers
            problem_biomarkers = [
                b for b in biomarkers
                if b.get("status") in ("low", "high", "critical_low", "critical_high")
            ]
            
            if not problem_biomarkers:
                return {}
            
            biomarker_text = self._format_biomarkers_for_prompt(problem_biomarkers)
            
            profile_text = ""
            if patient_profile:
                profile_text = f"\n–ü—Ä–æ—Ñ–∏–ª—å –ø–∞—Ü–∏–µ–Ω—Ç–∞: {json.dumps(patient_profile, ensure_ascii=False)}"
            
            prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –≤ –∞–Ω–∞–ª–∏–∑–∞—Ö –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ë–ê–î–æ–≤ –∏ —Ç–æ–≤–∞—Ä–æ–≤ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω–µ.
            
–û—Ç–∫–ª–æ–Ω–µ–Ω–∏—è:
{biomarker_text}
{profile_text}

–í–µ—Ä–Ω–∏ JSON:
{{
    "biomarker_keywords": {{
        "CODE": ["keyword1", "keyword2"]
    }},
    "general_keywords": ["keyword3", "keyword4"]
}}
"""
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system", 
                        "content": "–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –ø–æ–∏—Å–∫—É –ë–ê–î–æ–≤. –ì–µ–Ω–µ—Ä–∏—Ä—É–π —Ç–æ—á–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä: '–ñ–µ–ª–µ–∑–æ —Ö–µ–ª–∞—Ç', '–í–∏—Ç–∞–º–∏–Ω D3', '–û–º–µ–≥–∞-3')."
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.3,
                response_format={"type": "json_object"},
            )
            
            result = json.loads(response.choices[0].message.content)
            return result
            
        except Exception as e:
            logger.error(f"Keyword generation failed: {e}")
            return {}

    async def generate_recommendations(
        self,
        biomarkers: List[Dict[str, Any]],
        available_products: List[Dict[str, Any]],
    ) -> List[Dict[str, Any]]:
        """
        Generate product recommendations based on biomarker deficiencies.
        
        Args:
            biomarkers: List of biomarkers with status
            available_products: List of products from catalog
            
        Returns:
            List of recommendations with reasons
        """
        if not settings.openai_api_key or not available_products:
            return self._fallback_recommendations(biomarkers, available_products)
        
        try:
            # Filter biomarkers that need attention
            problem_biomarkers = [
                b for b in biomarkers
                if b.get("status") in ("low", "high", "critical_low", "critical_high")
            ]
            
            if not problem_biomarkers:
                return []
            
            # Prepare data for prompt
            biomarker_text = self._format_biomarkers_for_prompt(problem_biomarkers)
            products_text = self._format_products_for_prompt(available_products[:50])
            
            prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π –≤ –∞–Ω–∞–ª–∏–∑–∞—Ö –ø–æ–¥–±–µ—Ä–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–æ–±–∞–≤–∫–∏ –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞.

–û—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –≤ –∞–Ω–∞–ª–∏–∑–∞—Ö:
{biomarker_text}

–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã:
{products_text}

–í–µ—Ä–Ω–∏ JSON:
{{
    "recommendations": [
        {{
            "product_id": id_—Ç–æ–≤–∞—Ä–∞,
            "biomarker_code": "–∫–æ–¥_–±–∏–æ–º–∞—Ä–∫–µ—Ä–∞",
            "reason": "–ø–æ—á–µ–º—É —ç—Ç–æ—Ç —Ç–æ–≤–∞—Ä –ø–æ–º–æ–∂–µ—Ç",
            "priority": 1-5,
            "confidence": 0.0-1.0
        }}
    ]
}}"""
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "–¢—ã ‚Äî –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –ø–æ–¥–±–æ—Ä—É –ë–ê–î–æ–≤. –†–µ–∫–æ–º–µ–Ω–¥—É–π —Ç–æ–ª—å–∫–æ —Ç–µ —Ç–æ–≤–∞—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–ª—å–Ω–æ –º–æ–≥—É—Ç –ø–æ–º–æ—á—å —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –¥–µ—Ñ–∏—Ü–∏—Ç–∞–º–∏. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON."
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.3,
                max_tokens=2000,
                response_format={"type": "json_object"},
            )
            
            result = json.loads(response.choices[0].message.content)
            return result.get("recommendations", [])
            
        except Exception as e:
            logger.error(f"Recommendation generation failed: {e}")
            return self._fallback_recommendations(biomarkers, available_products)
    
    def _validate_extraction(self, result: Dict) -> Dict:
        """Validate and clean extracted data."""
        validated = {
            "lab_name": result.get("lab_name"),
            "analysis_date": result.get("analysis_date"),
            "biomarkers": [],
        }
        
        seen_codes = set()
        
        for bio in result.get("biomarkers", []):
            # Skip invalid entries
            if not bio.get("code") or bio.get("value") is None:
                continue
            
            try:
                value = float(bio["value"])
            except (ValueError, TypeError):
                continue
            
            # Normalize code from AI output to ensure standard codes
            raw_code = bio.get("code", "")
            code = self._normalize_biomarker_code(raw_code)
            
            logger.info(f"Biomarker processing: raw='{raw_code}', normalized='{code}', value={value}")
            
            # Skip duplicates (take first occurrence)
            if code in seen_codes:
                logger.info(f"Duplicate biomarker skipped: {code}")
                continue
            seen_codes.add(code)
            
            validated["biomarkers"].append({
                "code": code,
                "raw_name": bio.get("raw_name", ""),
                "value": value,
                "unit": bio.get("unit", ""),
                "ref_min": self._safe_float(bio.get("ref_min")),
                "ref_max": self._safe_float(bio.get("ref_max")),
            })
        
        return validated
    
    def _safe_float(self, value: Any) -> Optional[float]:
        """Safely convert value to float."""
        if value is None:
            return None
        try:
            return float(value)
        except (ValueError, TypeError):
            return None
    
    def _enrich_with_regex(self, result: Dict, ocr_text: str) -> Dict:
        """Find missing critical biomarkers using regex."""
        existing_codes = {b["code"] for b in result.get("biomarkers", [])}
        
        # Regex patterns for critical hormones that AI might miss
        critical_patterns = {
            "TSH": [
                r"(?:–¢–¢–ì|TSH|–¢–∏—Ä–µ–æ—Ç—Ä–æ–ø–Ω—ã–π)[^:\d]*[:\s]*([\d.,]+)",
            ],
            "FT4": [
                r"(?:–¢4\s*—Å–≤–æ–±|FT4|T4\s*free)[^:\d]*[:\s]*([\d.,]+)",
            ],
            "TEST": [
                r"(?:–¢–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω|Testosterone)[^:\d]*[:\s]*([\d.,]+)",
            ],
            "SHBG": [
                r"(?:–ì–°–ü–ì|SHBG|Sex\s*hormone)[^:\d]*[:\s]*([\d.,]+)",
            ],
            "PROL": [
                r"(?:–ü—Ä–æ–ª–∞–∫—Ç–∏–Ω|Prolactin)[^:\d]*[:\s]*([\d.,]+)",
            ],
            "FAI": [
                r"(?:–ò–°–¢|FAI|Index of Free Testosterone|–ò–Ω–¥–µ–∫—Å —Å–≤–æ–±\. —Ç–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω–∞)[^:\d]*[:\s]*([\d.,]+)",
            ]
        }
        
        for code, patterns in critical_patterns.items():
            if code in existing_codes:
                continue
                
            for pattern in patterns:
                match = re.search(pattern, ocr_text, re.IGNORECASE)
                if match:
                    try:
                        value_str = match.group(1).replace(",", ".")
                        # Clean value string from possible artifacts like trailing dots
                        value_str = value_str.rstrip(".")
                        value = float(value_str)
                        
                        logger.info(f"Regex rescue: found missing {code} = {value}")
                        
                        result["biomarkers"].append({
                            "code": code,
                            "raw_name": "Rescued by Regex",
                            "value": value,
                            "unit": "",
                            "ref_min": None,
                            "ref_max": None
                        })
                        existing_codes.add(code)
                        break
                    except ValueError:
                        continue
                        
        return result

    def _fallback_parse(self, ocr_text: str) -> Dict:
        """
        Fallback regex-based parser when AI is unavailable.
        Handles common formats from Russian labs.
        """
        biomarkers = []
        
        # Common patterns for lab results
        patterns = [
            # "–ì–µ–º–æ–≥–ª–æ–±–∏–Ω: 140 –≥/–ª (120-160)"
            r"([–ê-–Ø–∞-—èA-Za-z\s]+):\s*([\d.,]+)\s*([–∞-—è–ê-–Øa-zA-Z/¬≥¬≤]+)?\s*(?:\(?([\d.,]+)\s*[-‚Äì]\s*([\d.,]+)\)?)?",
            # "HGB 140 g/L"
            r"([A-Z]{2,5})\s+([\d.,]+)\s*([–∞-—è–ê-–Øa-zA-Z/¬≥¬≤]+)?",
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, ocr_text)
            for match in matches:
                if len(match) >= 2:
                    name = match[0].strip()
                    try:
                        value = float(match[1].replace(",", "."))
                    except ValueError:
                        continue
                    
                    unit = match[2] if len(match) > 2 else ""
                    ref_min = self._safe_float(match[3]) if len(match) > 3 else None
                    ref_max = self._safe_float(match[4]) if len(match) > 4 else None
                    
                    # Try to normalize code
                    code = self._normalize_biomarker_code(name)
                    
                    biomarkers.append({
                        "code": code,
                        "raw_name": name,
                        "value": value,
                        "unit": unit,
                        "ref_min": ref_min,
                        "ref_max": ref_max,
                    })
        
        return {
            "lab_name": None,
            "analysis_date": None,
            "biomarkers": biomarkers,
        }
    
    def _normalize_biomarker_code(self, name: str) -> str:
        """Normalize biomarker name to standard code."""
        name_lower = name.lower().strip()
        
        mappings = {
            # –ì–û–†–ú–û–ù–´ (–≤–∞–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –ø–µ—Ä–≤—ã–º–∏ –∏–∑-–∑–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –∏–º–µ–Ω)
            "–≥—Å–ø–≥": "SHBG",
            "shbg": "SHBG",
            "sex hormone": "SHBG",
            "–∏–Ω–¥–µ–∫—Å —Å–≤–æ–±": "FAI",
            "–∏—Å—Ç": "FAI",
            "fai": "FAI",
            "free androgen": "FAI",
            "—Ç–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω": "TEST",
            "testosterone": "TEST",
            "–ø—Ä–æ–ª–∞–∫—Ç–∏–Ω": "PROL",
            "prolactin": "PROL",
            "—Ç—Ç–≥": "TSH",
            "tsh": "TSH",
            "thyrotropin": "TSH",
            "—Ç–∏—Ä–µ–æ—Ç—Ä–æ–ø–Ω—ã–π": "TSH",
            "—Ç4": "FT4",
            "ft4": "FT4",
            "free t4": "FT4",
            "—Å–≤–æ–±–æ–¥–Ω—ã–π —Ç4": "FT4",
            "—Ç3": "FT3",
            "ft3": "FT3",
            "free t3": "FT3",

            # –û–°–¢–ê–õ–¨–ù–û–ï
            "–≥–µ–º–æ–≥–ª–æ–±–∏–Ω": "HGB",
            "hemoglobin": "HGB",
            "hgb": "HGB",
            "hb": "HGB",
            "—ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç—ã": "RBC",
            "rbc": "RBC",
            "–ª–µ–π–∫–æ—Ü–∏—Ç—ã": "WBC",
            "wbc": "WBC",
            "—Ç—Ä–æ–º–±–æ—Ü–∏—Ç—ã": "PLT",
            "plt": "PLT",
            "–≥–µ–º–∞—Ç–æ–∫—Ä–∏—Ç": "HCT",
            "hct": "HCT",
            "—Å–æ—ç": "ESR",
            "esr": "ESR",
            "–≥–ª—é–∫–æ–∑–∞": "GLU",
            "glucose": "GLU",
            "—Ö–æ–ª–µ—Å—Ç–µ—Ä–∏–Ω": "CHOL",
            "cholesterol": "CHOL",
            "–∞–ª—Ç": "ALT",
            "alt": "ALT",
            "–∞—Å—Ç": "AST",
            "ast": "AST",
            "–±–∏–ª–∏—Ä—É–±–∏–Ω": "BILI",
            "bilirubin": "BILI",
            "–∫—Ä–µ–∞—Ç–∏–Ω–∏–Ω": "CREA",
            "creatinine": "CREA",
            "–º–æ—á–µ–≤–∏–Ω–∞": "UREA",
            "urea": "UREA",
            "–∂–µ–ª–µ–∑–æ": "FE",
            "iron": "FE",
            "fe": "FE",
            "—Ñ–µ—Ä—Ä–∏—Ç–∏–Ω": "FERR",
            "ferritin": "FERR",
            "–≤–∏—Ç–∞–º–∏–Ω b12": "B12",
            "b12": "B12",
            "–≤–∏—Ç–∞–º–∏–Ω d": "D3",
            "d3": "D3",
            "–∫–∞–ª—å—Ü–∏–π": "CA",
            "calcium": "CA",
            "–º–∞–≥–Ω–∏–π": "MG",
            "magnesium": "MG",
        }
        
        for key, code in mappings.items():
            if key in name_lower:
                return code
        
        # Return original if no mapping found
        return name.upper()[:10]
    
    def _format_biomarkers_for_prompt(self, biomarkers: List[Dict]) -> str:
        """Format biomarkers for AI prompt."""
        lines = []
        for b in biomarkers:
            status = b.get("status", "unknown")
            status_emoji = {
                "normal": "‚úÖ",
                "low": "‚¨áÔ∏è",
                "high": "‚¨ÜÔ∏è",
                "critical_low": "‚ùå‚¨áÔ∏è",
                "critical_high": "‚ùå‚¨ÜÔ∏è",
            }.get(status, "‚ùì")
            
            ref_text = ""
            if b.get("ref_min") and b.get("ref_max"):
                ref_text = f" (–Ω–æ—Ä–º–∞: {b['ref_min']}-{b['ref_max']})"
            
            lines.append(
                f"{status_emoji} {b.get('code', 'N/A')}: "
                f"{b.get('value', 'N/A')} {b.get('unit', '')}{ref_text}"
            )
        
        return "\n".join(lines)
    
    def _format_products_for_prompt(self, products: List[Dict]) -> str:
        """Format products for AI prompt."""
        lines = []
        for p in products:
            ingredients = p.get("active_ingredients", "")
            benefits = p.get("health_benefits", "")
            
            lines.append(
                f"ID:{p['id']} | {p['name']} | "
                f"–°–æ—Å—Ç–∞–≤: {ingredients} | –ü–æ–ª—å–∑–∞: {benefits}"
            )
        
        return "\n".join(lines)
    
    def _generate_simple_summary(self, biomarkers: List[Dict]) -> str:
        """Generate simple summary without AI."""
        normal = [b for b in biomarkers if b.get("status") == "normal"]
        low = [b for b in biomarkers if b.get("status") == "low"]
        high = [b for b in biomarkers if b.get("status") == "high"]
        critical = [b for b in biomarkers if b.get("status") in ("critical_low", "critical_high")]
        
        summary = "üìä **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞**\n\n"
        
        if critical:
            summary += "‚ùå **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è:**\n"
            for b in critical:
                summary += f"- {b.get('code')}: {b.get('value')} {b.get('unit')}\n"
            summary += "\n"
        
        if low:
            summary += "‚¨áÔ∏è **–ù–∏–∂–µ –Ω–æ—Ä–º—ã:**\n"
            for b in low:
                summary += f"- {b.get('code')}: {b.get('value')} {b.get('unit')}\n"
            summary += "\n"
        
        if high:
            summary += "‚¨ÜÔ∏è **–í—ã—à–µ –Ω–æ—Ä–º—ã:**\n"
            for b in high:
                summary += f"- {b.get('code')}: {b.get('value')} {b.get('unit')}\n"
            summary += "\n"
        
        summary += f"‚úÖ **–í –Ω–æ—Ä–º–µ:** {len(normal)} –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π\n\n"
        summary += "‚ö†Ô∏è –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –ø—Ä–æ–∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è —Å –≤—Ä–∞—á–æ–º –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."
        
        return summary
    
    def _fallback_recommendations(
        self,
        biomarkers: List[Dict],
        products: List[Dict],
    ) -> List[Dict]:
        """Simple rule-based recommendations without AI."""
        recommendations = []
        
        # Simple mapping of biomarker deficiencies to product keywords
        deficiency_keywords = {
            "FE": ["–∂–µ–ª–µ–∑–æ", "iron", "fe"],
            "FERR": ["—Ñ–µ—Ä—Ä–∏—Ç–∏–Ω", "–∂–µ–ª–µ–∑–æ", "iron"],
            "B12": ["b12", "–±12", "–∫–æ–±–∞–ª–∞–º–∏–Ω"],
            "D3": ["–≤–∏—Ç–∞–º–∏–Ω d", "d3", "—Ö–æ–ª–µ–∫–∞–ª—å—Ü–∏—Ñ–µ—Ä–æ–ª"],
            "MG": ["–º–∞–≥–Ω–∏–π", "magnesium"],
            "ZN": ["—Ü–∏–Ω–∫", "zinc"],
            "CA": ["–∫–∞–ª—å—Ü–∏–π", "calcium"],
        }
        
        for bio in biomarkers:
            if bio.get("status") not in ("low", "critical_low"):
                continue
            
            code = bio.get("code", "").upper()
            keywords = deficiency_keywords.get(code, [])
            
            if not keywords:
                continue
            
            for product in products:
                product_text = (
                    f"{product.get('name', '')} "
                    f"{product.get('active_ingredients', '')} "
                    f"{product.get('health_benefits', '')}"
                ).lower()
                
                if any(kw in product_text for kw in keywords):
                    recommendations.append({
                        "product_id": product["id"],
                        "biomarker_code": code,
                        "reason": f"–°–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è –≤–æ—Å–ø–æ–ª–Ω–µ–Ω–∏—è –¥–µ—Ñ–∏—Ü–∏—Ç–∞ {code}",
                        "priority": 1 if bio.get("status") == "critical_low" else 2,
                        "confidence": 0.6,
                    })
        
        return recommendations

